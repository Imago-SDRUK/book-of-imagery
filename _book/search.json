[
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "",
    "text": "2.1 The promise of imagery for social science and policy\nWe are living in a fast changing society needing timely, spatially granular, and consistent information to adequately address complex social, economic, climatic, health and policy challenges. Challenges such as widening inequalities, uneven economic development, environmental vulnerability and persistent health disparities represent fundamental questions about places and how they change. Traditional sources, including censuses, household surveys and administrative registers remain indispensable. Yet, they are limited by cost, infrequency, selective coverage and latency in their collection and release. As a result, decision-makers and researchers often lack the evidence needed to monitor rapid change, anticipate emerging challenges, and evaluate the local effects of interventions.\nSatellite imagery offers a powerful and underexploited data solution. For more than half a century, satellites have orbited the Earth, capturing a detailed record of its surface and atmosphere. Initially designed for environmental monitoring, these data now represent an unparalleled observational archive of human and natural systems. Imagery captures the physical fabric of places, density of buildings, presence of green and blue spaces, road networks and informal settlements. It does this consistently across the globe and can capture change at multiple scales from local neighbourhood areas to national borders or entire continents. Unlike most traditional forms of social data, which are geographically fragmented and slow to update, imagery is comprehensive, timely and replicable.\nAn increasing volume of research has already demonstrated the promise of satellite imagery. Night-time lights have been used as proxies for economic activity and inequality across the globe (Henderson, Storeygard, & Weil, 2012) and sense changes in urban energy consumption (Rowe, Robinson & Patias 2022). Multispectral imagery has enabled the mapping of urban deprivation (Arribas-Bel, Patino, & Duque, 2017) and the monitoring of land use change in fast-growing regions (Brown et al., 2004). More recent advances in computer vision and machine learning further enhance our capacity to derive meaningful indicators from raw pixels, opening a new frontier for social research and policy. The challenge (and opportunity) lies in integrating these data into the mainstream to illuminate processes that have long remained in the shadows, to take satellites into the standard toolkit. Key to this challenge is making imagery more accessible and usable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-intro_promise",
    "href": "chapters/intro.html#sec-intro_promise",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "",
    "text": "WarningReview comment\n\n\n\nMost references are entered manually, we need to add them properly through BibTeX before releasing the first version.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-intro_unique",
    "href": "chapters/intro.html#sec-intro_unique",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "2.2 What makes satellite imagery unique?",
    "text": "2.2 What makes satellite imagery unique?\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: Consider if in sections 2.2 and 2.3, the text would flow better without sub-headings (e.g., 2.2.X). They all contain a single paragraph and perhaps the narrative would come together a bit better without the subheadings (the thematic nature of each paragraph is clear and super good I think, maybe it doesn’t need a subheading).\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nSP: I agree with DAB about having no sub heads. However, if subheads are required/felt necessary, they can be more `thematised’. So we can club comprehensive coverage + multi sensor coverage+ spatial resolution, temporal frequency + timeliness + retrospective power, and then conclude with the robustness. The story then reads like - satellite data has comprehensive coverage over space and time, and it can do better than surveys in some cases. Therefore, it is robust. That might improve the flow of this section.\n\n\nSatellite imagery is unlike most other forms of data used in the social sciences. The uniqueness of satellite imagery comes in the way multiple distinctive attributes compound to provide an observational resource that is comprehensive, consistent, granular and increasingly accessible. These qualities allow imagery to transcend the limitations of conventional social data sources and open new opportunities for analysis and policymaking.\n\n2.2.1 Comprehensive coverage\nSatellites view the entire Earth, offering data that extend across countries, regions and communities. This comprehensiveness can complement traditional data streams, like surveys, which are often limited by sample size, response bias or geographic reach. They can also enhance administrative registers in territories where governments maintain robust data infrastructures. Satellite imagery generates systematic records of all visible surfaces within its sensor range, covering remote rural areas, informal settlements and conflict-affected regions where social data are especially scarce (Kugler et al., 2019).\n\n\n2.2.2 Spatial resolution\nModern satellite platforms capture imagery at a range of spatial resolutions from kilometres to less than one metre per pixel. Coarser imagery provides consistent monitoring of land cover and climate-related variables at regional and national scales. Very high-resolution imagery can reveal building footprints, street patterns and even the configuration of green spaces at the neighbourhood level. This multi-scale capacity makes imagery a flexible resource: it can illuminate both macro-level transformations such as urban sprawl (Brown et al., 2004) and micro-scale differences in the built environment associated with health or wellbeing (Metzler et al., 2023).\n\n\n2.2.3 Temporal frequency and timeliness\nSatellite missions provide regular and predictable revisits ranging from daily (e.g. PlanetScope) to a few days or weeks (e.g. Sentinel-2 and Landsat). This cadence allows researchers and policymakers to generate consistent time series and monitor rapid changes in near real-time. For example, vegetation indices derived from multispectral imagery can track seasonal dynamics in urban greenness, while radar imagery can detect flood extents immediately after a storm. Such timeliness is difficult to achieve with traditional data sources, which are often updated only every few years. There is often a trade-off in satellite data between resolution and frequency, but technological advances such as nanosat constellations1 are constantly pushing outwards the frontier at which this trade-off takes place.\n\n\n2.2.4 Retrospective power\nSatellite programmes, such as Landsat, have been operating since the 1970s, creating an unparalleled archive of the Earth’s surface. These historical datasets allow researchers to reconstruct long-term patterns of land cover, urbanisation and environmental change, offering insights into trajectories that no survey or census could capture. The ability to ``look back in time’’ makes imagery especially valuable for understanding the cumulative effects of policies, economic shifts and climate change across decades (National Research Council, 1998). It also allows to fill the gaps that the lack of temporal consistency of some traditional social datasets introduce.\n\n\n2.2.5 Robustness to common data biases\nUnlike survey data, which rely on voluntary participation and may exclude hard-to-reach groups, satellite imagery does not require human consent or response to be generated. This makes it relatively immune to self-selection bias and more representative across space. While imagery has its own challenges (e.g. cloud cover and sensor noise), its systematic and global character ensures a level of consistency that complements traditional data sources (De Sherbinin et al., 2002).\n\n\n2.2.6 Multi-sensor richness\nImagery is not limited to visible light. Satellites measure across the electromagnetic spectrum, producing data on heat, vegetation health, surface water and air pollutants. Synthetic Aperture Radar (SAR) captures structural features through cloud and darkness; and hyperspectral sensors enable fine-grained detection of material properties. This diversity of sensors allows for the derivation of novel indicators, for example, from rooftop solar potential to urban heat island intensity that can directly inform pressing policy agendas in sustainability, prosperity and wellbeing (Deilami and Kamruzzaman, 2017).\n\n\n2.2.7 A unique source of social data\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: This is section is very good. I wonder if we should consider an additional feature to the boxes (like the one below) that highlights quotes from the text that we’d like the reader to be “imprinted on”.\n\nTogether, the above identified attributes position satellite imagery as a uniquely powerful form of smart data. Its comprehensiveness, resolution, timeliness, retrospective depth and sensor diversity create a multidimensional evidence base that is unmatched by conventional sources. What makes imagery transformative is not just its technical sophistication, but its capacity to bridge long-standing evidence gaps in the social sciences and policymaking, providing the foundations for more informed and timely decisions.\n\n\n\n\n\n\n\nTipBox 1.1: Mapping Urban Greenspace Inequalities\n\n\n\nUrban greenspace is increasingly recognised as a determinant of health and wellbeing. Yet official statistics on its distribution are often fragmented, inconsistent or outdated. Satellite imagery provides a systematic alternative. Using freely available Sentinel-2 multispectral data, researchers can derive the Normalised Difference Vegetation Index (NDVI) to estimate vegetation cover at fine spatial scales. DAB: Update here when GreenSpace data product is available to link here\nBy linking these imagery-derived measures to administrative health records, studies in the UK and elsewhere have shown systematic disparities in access to urban greenery, with deprived communities often having less exposure (Rugel et al., 2019; [REF]). For policymakers, this information is critical: it identifies green deserts within cities, supports the design of equitable planning policies and provides indicators to monitor the effectiveness of urban greening initiatives.\nThe key advantage is comprehensiveness and comparability. Unlike local audits or surveys, satellite imagery captures greenspace consistently across entire cities and regions, enabling cross-neighbourhood benchmarking and long-term monitoring. This makes it a unique input into strategies for healthy and sustainable urban development.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-intro_whynow",
    "href": "chapters/intro.html#sec-intro_whynow",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "2.3 Why now? The timely confluence of technological advances and shifting societal needs",
    "text": "2.3 Why now? The timely confluence of technological advances and shifting societal needs\n\n\n\n\n\n\nFor decades, the potential of satellite imagery to transform the social sciences and inform public policy has been recognised (Rindfuss & Stern, 1998; National Research Council, 1998). Yet until recently, this potential remained largely aspirational. The barriers were formidable: imagery was expensive, technically complex and difficult to process at scale; expertise was confined to environmental sciences and engineering, and the social science community lacked both the tools and the training to make effective use of complex and unstructured imagery data; in addition, the state-of-the-art technology did not allow the detail required to identify features and processes of interest in social contexts. Recently, key developments have transformed the landscape. We are witnessing a convergence of technological, institutional and societal changes that, together, create the right conditions for mainstreaming imagery in social research and policy.\n\n\n\n\n\n\n\nTipBox 1.2: From Pixels to Policy: Monitoring Rooftop Solar for Net Zero\n\n\n\nDAB: I’d only use this example if/when we know with certainty we’ll be getting into this space with a data product. Until then, I’d use a different example.\nA example that illustrates why satellite imagery is at an inflection point for social science and policy. Achieving net zero requires detailed knowledge of how households and businesses are adopting renewable technologies, yet official statistics on rooftop solar installation are often incomplete, delayed, or inconsistently reported across regions.\nRecent advances in computer vision and high-resolution imagery now allow automated detection of solar panels from space. Convolutional neural networks can be trained to recognise the distinctive spectral and geometric patterns of panels, producing accurate counts at building level and aggregating them to neighbourhoods or local authorities (e.g. Malof et al., 2016; Yu et al., 2018). When combined with socio-economic and housing data, these imagery-derived indicators help identify where adoption is lagging, highlight inequalities in access to green technology and guide targeted policy incentives.\nCrucially, these analyses can be updated regularly, tracking quarterly or even monthly uptake, and providing policymakers with near real-time evidence that would be prohibitively costly through surveys or administrative reporting alone. This example demonstrates how the convergence of new sensors, machine learning and demand for localised evidence makes imagery not just a complementary resource but a core component of the evidence infrastructure for sustainability and wellbeing.\n\n\n2.3.1 Proliferation and democratisation of satellites\nThe number of satellites orbiting the Earth has grown exponentially. After decades of roughly 150 satellite launches per year (1957–2012), annual launches surged to about 600 in 2019, 1,200 in 2020, and 2,470 in 2022 (United Nations Office for Outer Space Affairs (UNOOSA) 2023). Public programmes such as the European Space Agency’s Sentinel missions and NASA’s Landsat archive provide high-quality data freely and openly, while private constellations like Planet or Maxar deliver near-daily high-resolution imagery. Launch costs have plummeted, fuelled by commercial providers and advances in satellite miniaturisation (Sweeting 2018). The result is not only more satellites but more diverse sensors—optical, radar, hyperspectral and thermal offering unparalleled coverage of the Earth’s surface. What was once the preserve of specialised agencies is now accessible to researchers, policymakers and even the general public.\n\n\n2.3.2 Advances in resolution and sensor capability\nAlongside this expansion of satellite availability has come a dramatic improvement in the quality of imagery. Spatial resolution has increased from kilometres to sub-metre detail; temporal resolution has improved to daily or even multiple daily revisits; and spectral resolution has grown into hyper-spectral imagery that enables the measurement of heat, vegetation stress, air pollutants and urban morphology. These advances expand the analytical frontier: for example, DAB: we already have this example a couple of times above, consider including another one SP: I changed it tracking micro-greenspaces (Ramdani 2024), or monitoring the impacts of heatwaves on vulnerable populations [REF], or estimating contamination in agricultural soils (Yao et al. 2024). Such detail is key for understanding the intersection of environmental exposures, health and social inequality at scales that matter for policy.\n\n\n2.3.3 Revolution in computation and artificial intelligence\nRaw pixels alone are not enough. The primary value of imagery relates to the transformation of raw pixels into meaningful indicators. This is what Imago terms the “pixel-to-metric” challenge. Until recently, this process was limited by computational bottlenecks. Advances in machine learning and computer vision, combined with the rise of cloud computing and high-performance infrastructures, have fundamentally altered this landscape. Modern neural networks can extract building footprints, classify land cover or estimate deprivation with remarkable accuracy (Arribas-Bel 2017). Cloud platforms such as Google Earth Engine make it possible to analyse terabytes of imagery without local supercomputers. And the open source revolution that has powered many of these advances has democratised access to knowledge that used to required extremely advanced domain training. These factors have all contributed to lowering the barrier to entry for social researchers and policymakers.\n\n\n2.3.4 Easier access and integration with existing data ecosystems\nEqually transformative are the changes in data access. Imagery has also benefitted from the rise of data science over the last two decades, and is increasingly delivered through portals, APIs and interoperable formats (Jacobsen et al., 2020). This accessibility means that imagery can be linked to household surveys, administrative records or longitudinal cohort studies, allowing researchers to integrate contextual measures of environment, housing, or infrastructure into existing datasets. Such integration bridges the long-standing gap between social data on individuals and contextual data on places, creating powerful opportunities for spatially-explicit analysis and evidence-based policymaking. Yet, while an increasing number of satellite datasets are more accessible, their sheer volume and complex, unstructured nature remain a major challenge for most social scientists and policy makers to use and analyse imagery. This is a key barrier that Imago will tackle.\n\n\n2.3.5 Growing societal demand for timely, granular evidence\nTechnological advances alone would not be relevant if demand was absent. The societal context has shifted dramatically. Some of the most pressing challenges, including the climate emergency, health inequalities, housing crises and uneven regional development, all require data that are timely, spatially detailed and robust. Policymakers seek indicators that can capture the dynamics of local communities, monitor change in near real time and evaluate the impacts of interventions. Imagery is uniquely placed to meet this demand, offering consistent coverage at scales from a national to neighbourhood scale. In this sense, the supply of new imagery technologies is met with an urgent demand for better evidence in sustainability, prosperity and wellbeing.\n\n\n2.3.6 An inflection point for social research and policy\nTaken together, these changes may mark an inflection point. The barriers that historically confined imagery to niche environmental applications are being lowered. The convergence of cheaper and plentiful satellites, improved sensors, powerful computational methods, more accessible platforms, and pressing policy needs creates a window of opportunity. For the first time, imagery can become a mainstream data source for social research and policymaking. The challenge in front of us is to ensure the opportunity is seized: to build the infrastructure, capacity, and community that can make imagery usable, useful, and used across disciplines.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-intro_case",
    "href": "chapters/intro.html#sec-intro_case",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "2.4 The case for social science and policy use",
    "text": "2.4 The case for social science and policy use\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipBox 1.3: Detecting Informal Settlements and Housing Inequality for Inclusive Policy\n\n\n\nCurrently, informal settlements house over a billion people globally, with this number expected to increase substantially over the next 30 years (United Nations, 2023). Yet, they are often absent from official statistics and maps. This invisibility perpetuates exclusion, making it difficult for governments and international organisations to target investments in housing, sanitation, and health.\nSatellite imagery offers a way forward. High-resolution optical data, combined with machine learning classifiers, can detect the dense, irregular patterns characteristic of informal housing. Studies in sub-Saharan Africa and South Asia have demonstrated that imagery-based maps of settlement extent align closely with ground surveys, but can be produced faster, at lower cost, and with full coverage (Kuffer et al., 2016; Mahabir et al., 2018).\nFor policymakers, this capacity is transformative. Imagery can reveal previously unmapped communities, track their expansion over time, and help allocate resources more equitably. By integrating imagery with household surveys or administrative records, it becomes possible to link population characteristics with environmental exposures, providing a fuller picture of vulnerability and need.\nImportantly, this is also relevant in advanced economies such as the UK, where fine-grained spatial data can identify pockets of deprivation, housing precarity, or poor living conditions. Deriving granular insights from satellite data can enhance local authorities’ ability to design targeted, place-based interventions, aligning with the UK’s broader Levelling Up agenda.\nThis example illustrates the central case for imagery in social science and policy. It addresses critical data gaps in contexts where conventional sources are absent, unreliable or prohibitively expensive, enabling more inclusive and responsive decision-making.\n\nEvery second of human existence is now recorded from space. The challenge is no longer availability — it’s use. Despite a world of data being generated, a persistent gap remains between what satellites capture and what reaches policy makers’ hands. Pioneers have already shown how imagery can move the needle. Yet broader impact requires removing the frictions that keep this data out of reach. Imago bridges this gap.\n\n2.4.1 Persistent gaps in evidence\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nSP: I feel this sub section is too far down, it should be up in the beginning. It is the gap we are bridging, and therefore the raison d’etre for the BoI. If we justify it in the penultimate subsection, it feels too late to talk about it. My vote would be to put it in the intro to 2.2.\n\nAcross social research and policy, an enduring challenge is the lack of timely, reliable and spatially detailed data. Inequalities in health, prosperity and wellbeing often manifest at local scales: between neighbourhoods, across urban–rural divides or within regions. Yet, the data streams traditionally used to study these questions rarely provide the necessary resolution or frequency. Censuses are comprehensive but infrequent. Household surveys are costly and often geographically limited. Administrative data can be inconsistent or inaccessible due to privacy and governance restrictions. These gaps are especially acute in areas where policy demand is greatest: monitoring the uneven impacts of climate hazards, evaluating local housing markets, or designing interventions to address health disparities.\nSatellite imagery directly addresses these shortcomings. Its global, repeated coverage provides a spatial and temporal granularity rarely achievable with traditional data, offering opportunities to fill evidence gaps that constrain research and policymaking. Just as importantly, this value is entirely additive rather than substitutive: satellite data complement traditional social data, help stretch their value, and provide a multiplier effect that increases the value proposition of traditional data.\n\n\n2.4.2 Applications across domains\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: This section feel a bit unfinished. Perhaps it needs a better intro to show it is a list of areas where satellites have already moved the needle.\n\nThe potential of imagery has been demonstrated through a growing body of research showcasing its promise across multiple relevant domains, for example:\nEconomic development and inequality: Night-time light intensity has been used as a proxy for local economic activity, enabling estimates of growth in regions lacking reliable national accounts (Henderson et al., 2012). Studies combine multispectral imagery with machine learning to predict poverty at high spatial resolution (e.g. Jean et al., 2016), supporting targeted development interventions.\nUrbanisation and housing: Imagery provides indicators of urban expansion, building density, and settlement form. These measures are critical for understanding sprawl, housing affordability, and infrastructure provision (Brown et al., 2004). They also allow policymakers to track progress towards sustainable urban development goals.\nEnvironment and health: Imagery-derived measures of greenness, heat and pollution exposure can be derived and linked to individual and population health outcomes. These insights reveal systematic inequalities in environmental quality, with direct implications for urban planning and public health policy (Venter et al. 2023).\nDisaster response and climate adaptation: Rapid imagery analysis following floods, fires, or earthquakes enables near-real-time damage assessment. Such evidence supports humanitarian response and informs longer-term resilience planning (Shafapourtehrany et al. 2023).\n\n\n2.4.3 Complementarity and integration\nThe greatest potential of imagery lies in data integration with other data sources. Imagery-derived indicators can be linked with household or cohort surveys to provide rich contextual measures of local environment, infrastructure and housing conditions. For example, linking greenspace indices to health records can illuminate associations between neighbourhood environments and mental wellbeing. Similarly, combining imagery-based poverty maps with demographic data can support more equitable allocation of resources.\nThis integrative capacity allows imagery to act as a bridge between individual-level data and the broader characteristics of places, enabling multilevel analyses that capture the interaction between people and their environments. It also aligns with the growing demand in policymaking for place-based evidence that reflects the lived experience of communities rather than national averages (OECD 2025).\n\n\n2.4.4 Towards useful, usable and used imagery\nThe case for social research and policy use can be summarised as a matter of timing and translation. The technological advances described in Section 2.3 imply that, for the first time, imagery is poised to become a routine part of the evidence base. But realising this potential requires making imagery usable, useful, and used:\n\nUseful, by co-producing data products with stakeholders to ensure relevance to research and policy questions.\nUsable, by lowering technical barriers through open platforms, user-friendly interfaces, and interoperable data formats.\nUsed, by embedding imagery into established data ecosystems, training communities of practice, and demonstrating impact through visible policy applications.\n\nBy addressing these three pillars, imagery can evolve from a promising niche resource to a cornerstone of evidence-based social science and policymaking. The case is not only academic, it is practical and aligned with the growing demand for timely, localised and equitable data infrastructures.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-intro_barriers",
    "href": "chapters/intro.html#sec-intro_barriers",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "2.5 Barriers and challenges",
    "text": "2.5 Barriers and challenges\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: add additional pass\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nSP: Made edits for flow and readability, please check.\n\n\nDespite its promise, the widespread adoption of imagery in social science and policy remains constrained. There are broadly three classes of frictions - in processing, in understanding, and finally, in use.\nProcessing satellite data is technically complex, imagery is large in volume, stored in arcane formats, and requires technical expertise as well as specialist computing infrastructure to use. Extracting metrics from pixels involves terabytes of data and advanced processing pipelines.\nThere is a translation gap, in as much as a pixel is meaningless to a policy maker. The practitioners in need of this data do not work with raw imagery, but with interpretable measures (e.g. building density, greenspace exposure). The process of making raw imagery useful is often as demanding as processing it. Moreover, training in imagery analysis is largely absent from social science curricula, leaving potential users without the skills or resources to engage with these data.\nFinally, using high resolution imagery requires careful consideration. The ethical and governance concers associated with these exercises are not trivial. Very high-resolution imagery raises privacy issues, particularly when combined with other sensitive data sources. Appropriate protocol for data access, analysis and output release are needed.\nDespite decades of availability, these barriers have prevented imagery from entering the mainstream of social science and policy. Addressing these constraints requires sustained investment in infrastructure, capacity building and ethical governance. Imago has been designed to tackle these challenges.\n\n\n\n\nArribas-Bel, Jorge E. AND Duque, Daniel AND Patino. 2017. “Remote Sensing-Based Measurement of Living Environment Deprivation: Improving Classical Approaches with Machine Learning.” PLOS ONE 12 (5): 1–25. https://doi.org/10.1371/journal.pone.0176684.\n\n\nOECD. 2025. Place-Based Policies for the Future. OECD Regional Development Studies. Paris: OECD Publishing. https://doi.org/10.1787/e5ff6716-en.\n\n\nRamdani, Fatwa. 2024. “A Very High-Resolution Urban Green Space from the Fusion of Microsatellite, SAR, and MSI Images.” Remote Sensing 16 (8): 1366.\n\n\nShafapourtehrany, M., M. Batur, F. Shabani, B. Pradhan, B. Kalantar, and H. Özener. 2023. “A Comprehensive Review of Geospatial Technology Applications in Earthquake Preparedness, Emergency Management, and Damage Assessment.” Remote Sensing 15 (7): 1939. https://doi.org/10.3390/rs15071939.\n\n\nSweeting, Martin N. 2018. “Modern Small Satellites-Changing the Economics of Space.” Proceedings of the IEEE 106 (3): 343–61.\n\n\nUnited Nations Office for Outer Space Affairs (UNOOSA). 2023. “Our Common Agenda Policy Brief 7: For All Humanity – the Future of Outer Space Governance.” https://www.unoosa.org/res/oosadoc/data/documents/2023/a77/a77crp_1add_6_0_html/our-common-agenda-policy-brief-outer-space-en.pdf.\n\n\nVenter, Z. S., H. Figari, O. Krange, and V. Gundersen. 2023. “Environmental Justice in a Very Green City: Spatial Inequality in Exposure to Urban Nature, Air Pollution and Heat in Oslo, Norway.” Science of The Total Environment 858: 160193. https://doi.org/10.1016/j.scitotenv.2022.160193.\n\n\nYao, Liwei, Mingjie Xu, Yihui Liu, Ruiqing Niu, Xueling Wu, and Yingxu Song. 2024. “Estimating of Heavy Metal Concentration in Agricultural Soils from Hyperspectral Satellite Sensor Imagery: Considering the Sources and Migration Pathways of Pollutants.” Ecological Indicators 158: 111416.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#footnotes",
    "href": "chapters/intro.html#footnotes",
    "title": "2  Introduction: Why Imagery, Why Now?",
    "section": "",
    "text": "Fleets of shoe-box sized satellites that can obtain ever higher resolution at very high frequencies.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction: Why Imagery, Why Now?</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html",
    "href": "chapters/image-data.html",
    "title": "3  Satellite Imagery Data",
    "section": "",
    "text": "3.1 Introduction\nDAB: this first para feels a bit too technical for a start. Massage to do a bit more hand-holding of the reader. Satellite imagery constitutes one of the most powerful sources of information for understanding the Earth’s surface and its dynamic processes. Defined broadly as grid-based or raster data, where the Earth’s surface is represented as a matrix of pixels (or “grid cells”), each with a value corresponding to a specific measurement, captured by sensors mounted on orbital platforms. These data encompass a range of spectral, spatial, temporal, and radiometric characteristics that distinguish them from traditional, ground-based environmental observations. Unlike airborne systems that typically conduct surveys using aircraft such as small to medium-sized planes, helicopters, or drones (UAVs), or in situ field measurements, satellite data provide consistent, synoptic coverage across national and continental scales, enabling systematic monitoring over time.\nSince the launch of Sputnik 11 in 1957 and Landsat 12 in 1972, the satellite industry has experienced profound change. Satellite remote sensing has rapidly advanced alongside improvements in sensor technology, data storage over the last seventy years. What used to be a domain comprising a few national space agencies has evolved into a vibrant ecosystem that also encompasses private companies, public–private partnerships, and small satellite constellations (Undseth, Jolly, and Olivari 2021). Today, hundreds of satellites operated by governments and private companies provide images with a level of detail and frequency that would have been impossible just a decade ago. Simultaneously, developments in cloud computing and machine learning have substantially simplified the storage, processing and analysis of large volumes of high-resolution data. For researchers, these advances mean unparalleled access to timely and detailed observations of the Earth’s surface, frequently updated on a daily or even hourly basis. This chapter introduces the main types of satellite imagery, how they are collected and prepared for analysis, and common methods used to interpret them.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#chapter-objectives",
    "href": "chapters/image-data.html#chapter-objectives",
    "title": "3  Satellite Imagery Data",
    "section": "3.2 Chapter Objectives",
    "text": "3.2 Chapter Objectives\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: I really like the practice of setting out the chapter with a short section like this frontloading what the reader will learn in it. Perhaps we should make it part of the standard “chapter template”? To be discussed as a team.\n\n\nIntroduce key concepts and terminology associated with satellite imagery.\n\nSituate satellite data within the wider geospatial data ecosystem, comparing it with traditional data collection methods.\n\nDescribe the main sensor types, platforms, and missions, highlighting their strengths and constraints.\n\nExplain acquisition pathways, preprocessing workflows, and common analytical approaches.\n\nHighlight the value of satellite imagery for environmental monitoring, urban planning, and disaster response, emphasising its role in supporting informed decision-making at multiple scales.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#fundamentals-of-satellite-imagery",
    "href": "chapters/image-data.html#fundamentals-of-satellite-imagery",
    "title": "3  Satellite Imagery Data",
    "section": "3.3 Fundamentals of Satellite Imagery",
    "text": "3.3 Fundamentals of Satellite Imagery\n\n3.3.1 Resolution Dimensions\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: Expand/reshape into “how to think about satellite resolution” as a social scientist. One way could be by starting with a definition of resolution that is relevant for social scientists, then mapping that onto satellites, and providing much of the detail that’s already below.\n\nUnderstanding the concept of resolution is critical when working with satellite imagery. For social scientists, it is crucial to select a level of detail that allows social and economic processes to be observed meaningfully. Such choices might involve choosing a spatial resolution fine enough to capture local variation in livelihoods or a temporal resolution frequent enough to measure environmental or economic change over time. Each type of resolution describes a different aspect of how satellite data captures and represents features on the Earth’s surface. Together, they determine the usefulness of the imagery for particular applications. The four main types of resolution are spatial, temporal, spectral, and radiometric resolution. A summary of these differences is presented in Table 3.1 along with a visual depiction of their main differences in Figure 3.1.\n\n\n\nTable 3.1: Comparison of the four key resolution dimensions in satellite imagery.\n\n\n\n\n\n\n\n\n\n\n\nResolution Type\nDefinition\nExample Satellites / Sensors\nTypical Applications\n\n\n\n\nSpatial Resolution\nSize of ground area represented by each pixel.\nWorldView-3 (0.31 m), Sentinel-2 (10 m), MODIS (250–1000 m)\nUrban planning, infrastructure monitoring, land cover classification\n\n\nTemporal Resolution\nFrequency with which a satellite revisits the same location.\nPlanetScope (daily), Sentinel-2 (5 days with constellation), Landsat 8 (16 days)\nChange detection, crop monitoring, disaster response\n\n\nSpectral Resolution\nNumber and width of spectral bands captured.\nSentinel-2 (13 bands), Hyperion (220 bands)\nVegetation health, mineral mapping, environmental analysis\n\n\nRadiometric Resolution\nSensor’s sensitivity to differences in reflectance or brightness.\nLandsat 8 (12-bit), MODIS (12-bit)\nVegetation stress detection, water quality, surface temperature analysis\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.1: Satellite imagery resolution types.DAB: let’s discuss the use of AI in figures.\n\n\n\n\nSpatial resolution, one of the most commonly considered indicators of imagery usefulness, refers to the ground area represented by a single pixel in a satellite image. It determines the level of detail visible in the data. High spatial resolution, such as that offered by WorldView-3 (0.31 m) (n.d.a), enables the identification of fine-scale features like individual vehicles or small buildings (see example in Figure 3.2). In contrast, moderate to low spatial resolution sensors such as MODIS (250–1000 m) are better suited to observing broader phenomena like regional vegetation patterns or land cover changes.\n\n\n\n\n\n\nFigure 3.2: Comparison of different remote sensing images from data sources for mapping seagrass habitats, illustrating how spatial resolution varies across platforms. From left to right: drone imagery, WorldView-2 Panchromatic, WorldView-2 Multispectral, PlanetScope, Sentinel-2, and Landsat 8. Each panel highlights the trade-offs between spatial resolution, cost, spectral/temporal coverage, and availability, with advantages shown in green and limitations in red. Source: Levi Westerveld, GRID-Arendal (link). DAB: do we have the rights to reproduce this? Ideally, we’d rely on figures of our own to illustrate concepts like this.\n\n\n\n\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: [Applying to the rest of this section] This is a great start on how to introduce these concepts here. I think it needs a further pass to turn it into something that retains the message but it’s conveyed in a way that resonates more with social researchers, with the concepts they’re used to, and with the realities they work with. In part I think it’s about the tone, in part is about how we translate foreign concepts (e.g., spectral, wavelengths, bands). Perhaps it’s also about being less heavy on the technical stuff of “how it works” and a bit more on “what that means” for how it can be used in relevant use cases.\n\nTemporal resolution defines how frequently a satellite captures imagery of the same geographic location. This is essential for observing changes over time, particularly in dynamic or rapidly evolving environments. Satellites with high temporal resolution, such as PlanetScope, can image locations on a near-daily basis, which is valuable for monitoring crop growth, flood events, or wildfire spread. Others, such as Landsat 8, revisit the same location every 16 days, making them more appropriate for long-term environmental monitoring (Wulder et al. 2012).\nSpectral resolution is the ability of a sensor to detect and differentiate between various wavelengths of electromagnetic radiation. It is determined by the number of spectral bands and their widths. Multispectral sensors like Sentinel-2, which captures data in 13 bands, are suitable for general environmental monitoring. Hyperspectral sensors such as Hyperion, which collects data in 220 narrow bands, allow for fine discrimination of materials and are used in applications such as vegetation stress detection, mineral mapping, and pollution monitoring (Goetz 2009).\nRadiometric resolution refers to the sensitivity of a sensor in detecting slight differences in the intensity of radiation energy or brightness. It is expressed in bits, where higher values indicate a greater capacity to capture subtle variations in reflectance. For instance, an 8-bit sensor can record 256 levels of intensity, while a 12-bit sensor, like that on Landsat 8, can distinguish 4,096 levels. Higher radiometric resolution is especially useful in detecting nuanced surface conditions such as vegetation health or surface temperature gradients (Roy et al. 2014).\nEach resolution type plays a unique role in how satellite imagery can be interpreted and applied. For instance, high spatial resolution is vital for mapping urban features, while high spectral resolution is critical for distinguishing vegetation types or detecting subtle land changes. Most practical applications require balancing these types of resolution according to user needs and available data sources.\n\n\n3.3.2 Sensor Types\nSatellite sensors are tools that collect data about the Earth by detecting different types of electromagnetic energy. These sensors vary mainly in the portion of the electromagnetic spectrum they measure and the kind of data they produce. This spectrum includes all forms of light, from visible colours to wavelengths the human eye cannot see, such as infrared and microwave radiation (Campbell and Wynne 2011). Sensors fall into two main categories: passive sensors, which measure natural energy (usually sunlight) reflected or emitted from the Earth’s surface, and active sensors, which emit their own signal and measure how it reflects back (Jensen 2009). Understanding these differences is important because each type of sensor offers specific advantages depending on the observation needs.\nOptical sensors capture reflected sunlight in visible and near-infrared wavelengths, creating images similar to photographs. These are commonly used for land cover mapping and vegetation analysis (Campbell and Wynne 2011). Radar sensors, especially Synthetic Aperture Radar (SAR), send out microwave signals and measure the reflected response, allowing them to collect data in all weather conditions and at night (Ferretti, Prati, and Rocca 2002). Thermal sensors detect heat emitted from the Earth’s surface and are often used to monitor surface temperatures, detect wildfires, and assess building heat loss (Jensen 2009). Hyperspectral sensors record information across hundreds of narrow image bands (i.e., electromagnetic wavelengths), making it possible to detect subtle differences in surface materials, which is valuable in areas such as agriculture, environmental monitoring, and mineral exploration (Richards, Richards, et al. 2022; Goetz 2009).\nA summary of these sensor types is provided in Table 3.2. Each sensor type is suited to specific applications. Optical imagery is effective for monitoring crops, forests, and urban development. Radar is ideal in areas with frequent cloud cover or during night-time, for instance in flood mapping or infrastructure monitoring. Thermal imagery supports early wildfire detection and energy audits of buildings. Hyperspectral data enable detailed analysis of surface materials, supporting targeted agricultural practices and environmental assessments.\nThese sensors provide essential information for decision-making in areas such as disaster response, climate monitoring, land management, and infrastructure planning.\n\n\n\nTable 3.2: Comparison of satellite sensor types.\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nOptical (e.g. Landsat 8 OLI)\nRadar (e.g. Sentinel-1 SAR)\nThermal (e.g. MODIS, ECOSTRESS)\nHyperspectral (e.g. EO-1 Hyperion)\n\n\n\n\nEnergy Source\nPassive\nActive\nPassive\nPassive\n\n\nWavelength Range\nVisible and near-infrared\nMicrowave\nThermal infrared\nHundreds of narrow spectral bands\n\n\nKey Capabilities\nCaptures sunlight reflected from the Earth’s surface to produce imagery comparable to photographs.\nTransmits microwave pulses and measures the reflected signal to detect surface features and movement.\nMeasures heat naturally emitted from the Earth’s surface, providing information on temperature variations.\nRecords continuous spectral data across numerous narrow bands, enabling identification of surface materials.\n\n\nCommon Applications\nLand cover classification, vegetation health monitoring, urban growth analysis.\nFlood mapping, ground deformation studies, forest structure analysis.\nWildfire detection, urban heat island assessment, thermal efficiency studies.\nPrecision agriculture, mineral mapping, environmental quality assessments.\n\n\nStrengths\nHigh spatial resolution and easily interpretable images.\nWeather- and light-independent, consistent data acquisition.\nEffective for identifying temperature anomalies and thermal patterns.\nFine-grained detection of subtle spectral differences among materials.\n\n\nLimitations\nAffected by cloud cover and requires daylight.\nComplex to interpret, needs specialised processing.\nLower spatial resolution and less visual detail than optical sensors.\nLarge data volumes, sensitive to atmospheric conditions.\n\n\n\n\n\n\n\n\n3.3.3 Key Satellite Platforms and Missions\nDAB: this needs a gentler introduction that talks about the context and recent trends. Government-funded satellite missions play a crucial role in providing foundational Earth observation datasets. These datasets are typically made freely accessible to the public, making them invaluable resources for academic research, policy-making, and humanitarian efforts such as disaster relief and environmental monitoring. One of the most important examples is the Landsat program, which has been continuously capturing imagery since 1972 (n.d.b). This long-term archive provides a unique temporal record that allows researchers to study changes in land use, deforestation, urban expansion, and other landscape dynamics over decades (Wulder et al. 2019).\nBuilding on this, the Sentinel missions under the European Union’s Copernicus programme offer enhanced capabilities for Earth observation. Launched since 2014, the Sentinel satellites provide higher spatial and spectral resolution and more frequent revisit times than earlier systems, improving the ability to monitor rapid environmental changes. Each Sentinel mission concentrates on a particular aspect of the Earth’s surface. Sentinel-1 uses Synthetic Aperture Radar (SAR) to capture images regardless of cloud cover or daylight, which is critical for monitoring floods or infrastructure (Drusch et al. 2012; n.d.c). Sentinel-2 employs multispectral optical sensors, with a focus on land monitoring, capturing vegetation or soil cover, while Sentinel-3 provides data on the temperature of both sea and land surface, as well as topography of the sea surface (n.d.d). Sentinel-4 and Sentinel-5 were designed to monitor atmospheric composition for different geographies, whereas Sentinel-6 measures sea-surface height (n.d.d).\nDAB: I’d add an extra paragraph here on other government-backed missions (e.g., China, Japan, Brazil) to give the sense Western governments are not the only players on this anymore.\nComplementing these public missions, commercial satellite platforms have emerged, offering very high resolution (i.e., sub-metre) imagery often updated daily or more frequently. Companies like Maxar Technologies provide detailed images that can resolve objects such as individual vehicles or small buildings, enabling applications in infrastructure monitoring, urban planning, and disaster response where rapid, detailed information is essential.\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: Before getting into the new corporate players, I’d incldue a paragraph that reviews the “old space” companies (e.g., Airbus). They’re still very very relevant and, in some ways, provide some of the state of the art (e.g., highest resolution). Then I’d thread the paragraph below, introducing it as the “new space”, which is in many ways disrupting the old models (nanosat constellations, consumer optical hardware, etc.). In “new space”, I’d differentiate those that are working on more traditional sensors (optical like Planet, SAR like Umbra), and those with new types (e.g., SatVu with high resolution thermal; all the hyper-spectral craze, etc.).\n\nMore recently, constellations of small satellites operated by companies such as Planet have transformed Earth observation by offering near-daily global coverage at fine spatial resolutions of 3.7 metres. These small satellites, or “smallsats” (also called Doves), balance spatial resolution and temporal frequency, making it possible to track dynamic changes like crop growth, flooding, or urban development with unprecedented detail and frequency. However, this high temporal resolution often comes with higher costs and data management challenges (Curzi, Modenini, and Tortora 2020; n.d.e).\nTogether, these government and commercial systems provide a powerful and complementary range of satellite imagery options, supporting a wide variety of scientific, policy, and commercial applications. Live locations of many of these satellites can be tracked online via the satellitemap.space online platform.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#data-acquisition-and-accessibility",
    "href": "chapters/image-data.html#data-acquisition-and-accessibility",
    "title": "3  Satellite Imagery Data",
    "section": "3.4 Data Acquisition and Accessibility",
    "text": "3.4 Data Acquisition and Accessibility\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: Add intro paragraph here introducing with a summary of the goals of this section. It’s a really packed one and it can feel overwhelming.\n\n\n3.4.1 Sources of Satellite Imagery\nSatellite imagery is obtainable from open-access government missions and commercial providers. Public missions such as United States Geological Survey (USGS) Landsat programme and the European Space Agency’s (ESA) Sentinel satellites (part of the Copernicus programme) have played a crucial role in making Earth observation data widely accessible. These missions offer free, standardised, and globally consistent imagery that supports long-term environmental monitoring, disaster response, land use classification, and climate change research (Wulder et al. 2012; Drusch et al. 2012). The Landsat archive, in particular, provides the longest continuous record of Earth’s surface from space, dating back to 1972 (Wulder et al. 2019; Roy et al. 2014).\nIn contrast, commercial providers such as Maxar Technologies and Planet Labs deliver very high-resolution imagery with more frequent updates. These images, which can capture detail as fine as 30 cm, are well-suited to applications such as infrastructure monitoring, precision agriculture, and emergency management (Belward and Skøien 2015). However, this level of detail often comes at a cost. In this case, data from commercial providers is typically subject to strict licensing and usage fees, which can limit availability for academic or humanitarian purposes.\nTo bridge this gap, hybrid access models are emerging. Initiatives like NASA’s Commercial Smallsat Data Acquisition (CSDA) programme (n.d.f) and ESA’s Third Party Missions programme (n.d.g) allow researchers and non-profits to access commercial satellite imagery under subsidised agreements, expanding the reach of high-resolution data for scientific and public-good applications.\n\n\n3.4.2 Access Platforms and APIs\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: I’d reword the title to “Accessing satellite data” and provide a more general overview: start with how EO data have traditionally been accessed, then moving to innovations like API’s and cloud platforms, and then even add a paragraph about the new “cloud-native” generation of protocols (e.g., STAC) and file formats (e.g., COGs) that is more and more powering all offering of EO data.\n\nCloud-based platforms and application programming interfaces (APIs) have significantly transformed how users access and analyse satellite data. Cloud-based platforms are online environments that store large datasets and provide tools for processing them remotely, removing the need for users to download large files or maintain powerful local computers. APIs are software tools that allow users to interact with these platforms programmatically, enabling them to automate tasks such as searching for images, retrieving data, and running analyses.\nOne such platform is Google Earth Engine (GEE), which combines an extensive archive of satellite imagery, including Landsat, Sentinel, and MODIS, with powerful cloud computing tools that allow users to process data at global scale without needing to download large files or maintain local servers (Gorelick et al. 2017). GEE provides a user-friendly JavaScript and Python API that enables both interactive exploration and batch processing of satellite data. This has opened up Earth observation to a broader community, including researchers, practitioners, and students who may not have access to high-performance computing infrastructure. Through GEE’s platform, users can perform complex analyses such as land cover classification, deforestation tracking, and climate monitoring across large spatial and temporal extents. The combination of open data, cloud-based processing, and accessible programming tools makes GEE a foundational resource in the modern remote sensing landscape (Zhao et al. 2021; Mutanga and Kumar 2019; Cardille et al. 2024).\nOther platforms like the Copernicus Open Access Hub (n.d.h) and USGS EarthExplorer (Survey, n.d.) provide direct access to raw imagery and metadata from Sentinel and Landsat satellites. These portals support browsing, visual inspection, and batch downloads, which are particularly useful for researchers. Further, commercial providers such as Planet and Maxar also offer APIs that allow users to search, request, and download imagery programmatically. Some APIs even support satellite tasking, allowing users to request a new image over a specific location. These tools enable integration into automated workflows, making satellite data more usable in machine learning models, urban monitoring systems, and near-real-time environmental applications.\nAs satellite imagery becomes more detailed and abundant, managing these large datasets using traditional methods is increasingly difficult. At the same time, the cloud model (i.e., cheap and abundant storage and compute rented on infrastructure managed by dedicated large companies such as Google, Amazon, or Microsoft) that has taken over other parts of computing and tech appears as a good fit to tackle the challenge. Cloud-based solutions address this by using formats like Cloud Optimised GeoTIFFs (COGs), which let users load only the parts of a file they need, improving efficiency and reducing the need to download entire images (n.d.i). Further supporting these large datasets, platforms like Amazon Web Services (AWS), Google Earth Engine, and Microsoft’s Planetary Computer now host massive archives of satellite data from missions such as Landsat and Sentinel. Tools provided by services like GEE allow users to search, analyse, and integrate this data into applications without needing their own servers.\nDespite these advances, challenges remain. High storage and download costs can limit how much data users can afford to access. In addition, inconsistent metadata—how data is described and labelled—makes it harder to work across different systems. Most critically, access to cloud computing resources is uneven. Many researchers, especially in low-resource settings, may not have the internet connectivity or funding to take full advantage of these platforms (Lowndes et al. 2017). DAB: I think it’d be worth expanding this paragraph a bit by tayloring it to social researchers. How do these general challenges map onto more specific issues social scientists experience when dealing with satellite imagery?\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: 1. At some point in this section, it’d be good to add a paragraph on how this landscape of data access compares to that in the social sciences (where access mostly through the download of tables), what the key differences are, and some of the reasons behind it (e.g., data volume). This will help the reader connect with the message and relate to the new content. 2. I’ve brough into this section what used to be 3.4.4 because I think it fits the narrative and makes the text more coherent overall.\n\n\n\n3.4.3 Licensing and Cost\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: here again, it might be good to draw a connection to how licensing operates in the social sciences to help folks understand this landscape.\n\nLicensing models vary considerably and determine how satellite imagery can be used, shared, or modified. A licence is a legal agreement that outlines what users are allowed to do with a dataset. Open-access datasets, such as those provided by the Landsat and Sentinel missions, typically come with licences that permit free download, use, and redistribution (Wulder et al. 2012; Harris and Baumann 2015). These open licences promote transparency, reproducibility, and collaboration, especially in research and public policy contexts. Conversely, commercial imagery is often constrained by licences that prohibit redistribution or require substantial payment (Kim 2024), posing barriers to open science.\n\n\n3.4.4 Ethics\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: this is super interesting and one of the areas where we have legit advantage in covering. I’d expand this section a bit more (one or two more paragraphs) and try to bring in conversation with ethics debates in the social sciences.\n\nThere are also growing ethical concerns surrounding the use of satellite imagery. High-resolution images can capture detailed views of human activities and built environments, which may raise privacy issues, especially when the data are used in sensitive contexts such as humanitarian crises, armed conflict, or surveillance operations (Guida 2021; Avtar et al. 2021). In addition, a broader debate has emerged around the concept of data colonialism. This term refers to the idea that access to valuable data, in this context, commercial high-resolution imagery, is often dominated by institutions in wealthier countries (Thatcher, O’Sullivan, and Mahmoudi 2016). As a result, organisations and researchers in lower-income regions may face significant barriers to accessing the data needed for critical decision-making, scientific research, or disaster response. These imbalances risk reinforcing existing global inequalities in knowledge production and technological capacity.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#pre-processing-and-calibration",
    "href": "chapters/image-data.html#pre-processing-and-calibration",
    "title": "3  Satellite Imagery Data",
    "section": "3.5 Pre-processing and Calibration",
    "text": "3.5 Pre-processing and Calibration\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: I’m not sure this should be a section of its own in its current state. Consider folding into other parts or removing. It is also a very technical aspect. If we’re going to keep it, I’d suggest to frame it as the stuff end users don’t typically have to worry but is crucial and is taken care of before end-users (at least social folks) touch the data. We could compare it a bit with the Q&A processes that surveys and censuses go through by the producer agencies before they’re even released (they’re obviously different processes but I think there’s a parallel).\n\nBefore satellite imagery can be meaningfully analysed, it undergoes a series of pre-processing steps to ensure spatial accuracy, radiometric consistency, and suitability for the intended application. The main stages include:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#georeferencing-and-orthorectification",
    "href": "chapters/image-data.html#georeferencing-and-orthorectification",
    "title": "3  Satellite Imagery Data",
    "section": "3.6 Georeferencing and Orthorectification",
    "text": "3.6 Georeferencing and Orthorectification\nGeoreferencing is the process of linking a satellite image to real locations on the Earth’s surface so that every pixel corresponds to a specific point on a map. Orthorectification goes a step further by correcting distortions in the image that occur because the satellite was not looking straight down, the ground is uneven, or the Earth is curved. These steps make sure that features such as roads, buildings, or rivers are shown in the right place and at the correct scale. Without these corrections, measurements taken from the image could be inaccurate, which would affect tasks like tracking city growth, monitoring environmental change, or planning new infrastructure (Jensen 2009).\n\n3.6.1 Radiometric and Atmospheric Corrections\nOver time, satellite sensors can lose some of their accuracy, and different sensors may record slightly different values for the same location. Radiometric calibration is a way of adjusting the image so that the brightness and colours more accurately represent what is really on the ground. Atmospheric correction deals with the effects of the air between the satellite and the Earth’s surface. Sunlight can be scattered or absorbed by gases, dust, smoke, or water vapour in the atmosphere, which can change the way surfaces appear in the image. These corrections help ensure that the colours and brightness in the imagery are as close as possible to reality, making the data more reliable for studying vegetation, tracking climate patterns, or mapping land use (Jensen 2009; Campbell and Wynne 2011).\n\n\n3.6.2 Cloud Masking and Data Fusion\nClouds and the shadows they cast can block important details in satellite images, making it difficult to see the land or water underneath. To address this, automated methods such as the Fmask system (Zhu, Wang, and Woodcock 2015) can scan the image to find and remove the parts affected by clouds or their shadows. Landsat 8, for instance, also includes a dedicated Quality Assessment (QA) band that flags pixels affected by clouds, cloud shadows, snow, and other anomalies, which can be used to improve cloud masking (Missions 2019).\nAnother approach, called data fusion, combines information from different sources to fill in the gaps. For example, optical images (which rely on sunlight) can be merged with radar images (which can see through clouds), or multiple images taken on different days can be blended together. These techniques not only reduce the impact of clouds but can also make the images sharper, add more colour detail, or show changes over shorter time periods (Pohl and Van Genderen 1998).\n\n\n3.6.3 Handling Noise and Inconsistencies\nSatellite images can sometimes contain unwanted errors or ‘noise’ that make them harder to interpret. This noise might come from the sensor itself, interference from the atmosphere, or differences between images taken by different satellites or at different times. To improve image quality, specialists use various techniques to reduce this noise and correct inconsistencies. For example, filters can smooth out random speckles in radar images, and adjustments can be made to align images taken under different conditions. These steps help make the data clearer and more reliable for analysis (Maity et al. 2015; Idol, Haack, and Mahabir 2017).\n\n\n3.6.4 Derivation of Indices\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: I’d suggest to turn this into its own section (e.g., 3.7). This is very core to what Imago is about, and we should be able to write a good one on this that gives this step the relevance and credit we think it deserves. We will also be able to pull from all the experience in the product teams to write this well.\n\nSatellite images capture different types of light reflected from the Earth’s surface. By combining these light measurements in special ways called “indices,” it becomes easier to see and understand certain features. One common example is the Normalised Difference Vegetation Index (NDVI), which uses light reflected from plants to show how healthy the vegetation is. Healthy plants reflect more near-infrared light and less red light, so NDVI highlights areas with thriving greenery (Huete et al. 2002). Other indices help detect water, assess fire damage, or identify urban areas. These tools turn complex satellite data into simple, meaningful pictures that support environmental monitoring and decision-making.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#analytical-methods-and-tools",
    "href": "chapters/image-data.html#analytical-methods-and-tools",
    "title": "3  Satellite Imagery Data",
    "section": "3.7 Analytical Methods and Tools",
    "text": "3.7 Analytical Methods and Tools\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: I think we should make this into a separate chapter. It feels like so much for a single one to cover properly. We will also be working more on this as we advance data products and workshops, and there’s a lot of scope to do a really good job on this one. I’d suggest to take the content as it is now, and stuff it in a separate chapter on methods that we do not release officially on v0.1 in December, but that we keep to continue building on as we develop more workshop material, etc.\nI think there’s a really good opportunity here to turn this chapter into something super useful by presenting some of the standard stuff in satellite imagery but with a social science twist that really speaks to our audience and that cannot be found elsewhere. Let’s build on top of this in that direction.\n\nOnce satellite images are prepared, different techniques are used to extract useful information.\n\n3.7.1 Image Classification\nImage classification is a way to sort parts of a satellite image into meaningful groups, such as forests, water bodies, or urban areas. Some techniques rely on examples provided by experts to “teach” the computer what each category looks like (supervised classification), while others automatically find patterns without prior examples (unsupervised classification) (Lu and Weng 2007). More recently, advanced artificial intelligence methods, like deep learning, have been used to improve accuracy by recognising complex patterns in high-resolution images (Li et al. 2018). Figure 1 shows a recent 2024 land cover map for the UK that was derived from satellite imagery.\n\n\n\nDAB:Caption?\n\n\n\n\n3.7.2 Change Detection\nChange detection involves comparing images taken at different times to identify how the landscape has changed. This is useful for monitoring deforestation, urban growth, flood damage, or other environmental changes. Techniques range from visual comparison to GIS-based approaches (Lu et al. 2004), to more recent AI and deep learning methods (Ding et al. 2025). By spotting where and when changes happen, decision-makers can respond more quickly to issues or plan future developments.\n\n\n3.7.3 Object-Based Image Analysis\nUnlike methods that classify individual pixels, Object-Based Image Analysis (OBIA) groups nearby pixels into meaningful “objects” based on their shape, colour, and texture (Blaschke 2010). This approach is especially effective for identifying distinct features such as buildings, roads, or agricultural fields, providing more detailed and accurate results in complex environments.\n\n\n3.7.4 Time-Series Analysis and Spatio-Temporal Modelling\nTime-series analysis examines satellite data collected over multiple dates to observe trends and patterns over time, such as seasonal vegetation cycles or urban expansion (Zhang et al. 2003). Spatio-temporal modelling adds the dimension of space and time together to better understand how changes occur across different locations and periods.\n\n\n3.7.5 Software and Programming Tools\n\n\n\n\n\n\n\nWarningReview comment\n\n\n\nDAB: I wonder if this sub-section could also be expanded into a separate (shorter) chapter on software and tools to work with imagery. Something like we did in the GDS book but for this context:\nhttps://geographicdata.science/book/notebooks/02_geospatial_computational_environment.html\nWe will also have to build something like this for some of the workshops we’ll deliver, so I think it makes sense to consider from the start as its own chapter we can point all sorts of folks to.\n\nSpecialised software and programming languages help experts manage, analyse, and visualise satellite data. Tools like QGIS, ENVI, and SNAP provide user-friendly interfaces for working with geospatial data, while programming languages such as Python enable custom analyses through libraries like rasterio (Rasterio Developers 2024) and scikit-learn (Pedregosa et al. 2011). Cloud platforms, including Google Earth Engine (GEE), have further expanded access by allowing large-scale processing without needing powerful local computers (Gorelick et al. 2017).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#summary",
    "href": "chapters/image-data.html#summary",
    "title": "3  Satellite Imagery Data",
    "section": "3.8 Summary",
    "text": "3.8 Summary\nSatellite imagery offers a powerful way to observe and understand our planet from above, providing valuable information about the environment, cities, and natural resources. This chapter explored how these images are collected from both public and commercial sources, and the steps needed to prepare them for meaningful analysis. Ensuring accuracy through processes like correcting distortions and removing clouds is essential before the data can be used effectively. By applying various methods to classify land types, detect changes over time, and study patterns, satellite images become a vital tool for tracking environmental health, managing urban growth, and responding to natural disasters.\nBeyond the technical details, the use of satellite data holds great promise for addressing global challenges. It enables better decision-making by offering a clear, up-to-date picture of complex landscapes at local and global scales. Cloud-based platforms and new technologies have made this information more accessible to a wide range of users, from scientists to policymakers. However, challenges remain, such as ensuring fair access to high-resolution data and respecting ethical considerations. Overall, satellite imagery represents an important resource that can help society monitor change, protect ecosystems, and plan more sustainable futures.\n\n\n\n\nn.d.i. Cloud Optimized GeoTIFF. https://cogeo.org/.\n\n\n———. n.d.h. Copernicus. https://www.copernicus.eu/en/access-data/conventional-data-access-hubs.\n\n\n———. n.d.f. NASA. https://www.earthdata.nasa.gov/about/csda.\n\n\n———. n.d.c. ESA. https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-1.\n\n\n———. n.d.g. ESA. https://earth.esa.int/eogateway/missions/third-party-missions.\n\n\n———. n.d.d. ESA. https://www.esa.int/Applications/Observing_the_Earth/Copernicus/The_Sentinel_missions.\n\n\n———. n.d.e. Planet Labs. https://www.planet.com/products/satellite-monitoring/.\n\n\n———. n.d.b. USGS. https://www.usgs.gov/landsat-missions/landsat-1.\n\n\n———. n.d.a. WorldView. https://earth.esa.int/eogateway/missions/worldview-3.\n\n\nAvtar, Ram, Asma Kouser, Ashwani Kumar, Deepak Singh, Prakhar Misra, Ankita Gupta, Ali P Yunus, et al. 2021. “Remote Sensing for International Peace and Security: Its Role and Implications.” Remote Sensing 13 (3): 439.\n\n\nBelward, Alan S, and Jon O Skøien. 2015. “Who Launched What, When and Why; Trends in Global Land-Cover Observation Capacity from Civilian Earth Observation Satellites.” ISPRS Journal of Photogrammetry and Remote Sensing 103: 115–28.\n\n\nBlaschke, Thomas. 2010. “Object Based Image Analysis for Remote Sensing.” ISPRS Journal of Photogrammetry and Remote Sensing 65 (1): 2–16.\n\n\nCampbell, James B, and Randolph H Wynne. 2011. Introduction to Remote Sensing. Guilford press.\n\n\nCardille, Jeffrey A, Morgan A Crowley, David Saah, and Nicholas E Clinton. 2024. “Cloud-Based Remote Sensing with Google Earth Engine: Fundamentals and Applications.” Springer Nature.\n\n\nCurzi, Giacomo, Dario Modenini, and Paolo Tortora. 2020. “Large Constellations of Small Satellites: A Survey of Near Future Challenges and Missions.” Aerospace 7 (9): 133.\n\n\nDing, Lei, Danfeng Hong, Maofan Zhao, Hongruixuan Chen, Chenyu Li, Jie Deng, Naoto Yokoya, Lorenzo Bruzzone, and Jocelyn Chanussot. 2025. “A Survey of Sample-Efficient Deep Learning for Change Detection in Remote Sensing: Tasks, Strategies, and Challenges.” IEEE Geoscience and Remote Sensing Magazine.\n\n\nDrusch, Matthias, Umberto Del Bello, Sébastien Carlier, Olivier Colin, Veronica Fernandez, Ferran Gascon, Bianca Hoersch, et al. 2012. “Sentinel-2: ESA’s Optical High-Resolution Mission for GMES Operational Services.” Remote Sensing of Environment 120: 25–36.\n\n\nFerretti, Alessandro, Claudio Prati, and Fabio Rocca. 2002. “Permanent Scatterers in SAR Interferometry.” IEEE Transactions on Geoscience and Remote Sensing 39 (1): 8–20.\n\n\nGoetz, Alexander FH. 2009. “Three Decades of Hyperspectral Remote Sensing of the Earth: A Personal View.” Remote Sensing of Environment 113: S5–16.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nGuida, Emilio. 2021. “The Use of Satellites in Humanitarian Contexts.”\n\n\nHarris, Ray, and Ingo Baumann. 2015. “Open Data Policies and Satellite Earth Observation.” Space Policy 32: 44–53.\n\n\nHuete, Alfredo, Kamel Didan, Tomoaki Miura, E Patricia Rodriguez, Xiang Gao, and Laerte G Ferreira. 2002. “Overview of the Radiometric and Biophysical Performance of the MODIS Vegetation Indices.” Remote Sensing of Environment 83 (1-2): 195–213.\n\n\nIdol, Terry, Barry Haack, and Ron Mahabir. 2017. “Radar Speckle Reduction and Derived Texture Measures for Land Cover/Use Classification: A Case Study.” Geocarto International 32 (1): 18–29.\n\n\nJensen, John R. 2009. Remote Sensing of the Environment: An Earth Resource Perspective 2/e. Pearson Education India.\n\n\nKim, Young-Ju. 2024. “Commercial Use of Satellite Remote Sensing Data and Civil Liability.” Laws 13 (6): 77.\n\n\nLi, Ying, Haokui Zhang, Xizhe Xue, Yenan Jiang, and Qiang Shen. 2018. “Deep Learning for Remote Sensing Image Classification: A Survey.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 8 (6): e1264.\n\n\nLowndes, Julia S Stewart, Benjamin D Best, Courtney Scarborough, Jamie C Afflerbach, Melanie R Frazier, Casey C O’hara, Ning Jiang, and Benjamin S Halpern. 2017. “Our Path to Better Science in Less Time Using Open Data Science Tools.” Nature Ecology & Evolution 1 (6): 0160.\n\n\nLu, Dengsheng, Paul Mausel, Eduardo Brondizio, and Emilio Moran. 2004. “Change Detection Techniques.” International Journal of Remote Sensing 25 (12): 2365–2401.\n\n\nLu, Dengsheng, and Qihao Weng. 2007. “A Survey of Image Classification Methods and Techniques for Improving Classification Performance.” International Journal of Remote Sensing 28 (5): 823–70.\n\n\nMaity, Alenrex, Anshuman Pattanaik, Santwana Sagnika, and Santosh Pani. 2015. “A Comparative Study on Approaches to Speckle Noise Reduction in Images.” In 2015 International Conference on Computational Intelligence and Networks, 148–55. IEEE.\n\n\nMissions, Landsat. 2019. “Landsat 8 Data Users Handbook.” Landsat MISSIONS: Sioux Falls, SD, USA.\n\n\nMutanga, Onisimo, and Lalit Kumar. 2019. “Google Earth Engine Applications.” Remote Sensing. MDPI.\n\n\nPedregosa et al. 2011. Scikit-Learn: Machine Learning in Python. Journal of Machine Learning Research. Vol. 12. https://scikit-learn.org/stable/.\n\n\nPohl, Cle, and John L Van Genderen. 1998. “Review Article Multisensor Image Fusion in Remote Sensing: Concepts, Methods and Applications.” International Journal of Remote Sensing 19 (5): 823–54.\n\n\nRasterio Developers. 2024. Rasterio: Access to Geospatial Raster Data in Python. https://rasterio.readthedocs.io/en/latest/.\n\n\nRichards, John A, John A Richards, et al. 2022. Remote Sensing Digital Image Analysis. Vol. 5. Springer.\n\n\nRoy, David P, Michael A Wulder, Thomas R Loveland, Curtis E Woodcock, Richard G Allen, Martha C Anderson, Dennis Helder, et al. 2014. “Landsat-8: Science and Product Vision for Terrestrial Global Change Research.” Remote Sensing of Environment 145: 154–72.\n\n\nSurvey, USGS - U. S. Geological. n.d. EarthExplorer. https://earthexplorer.usgs.gov/.\n\n\nThatcher, Jim, David O’Sullivan, and Dillon Mahmoudi. 2016. “Data Colonialism Through Accumulation by Dispossession: New Metaphors for Daily Data.” Environment and Planning D: Society and Space 34 (6): 990–1006.\n\n\nUndseth, Marit, Claire Jolly, and Mattia Olivari. 2021. “Evolving Public-Private Relations in the Space Sector.” OECD Science, Technology and Industry Policy Papers.\n\n\nWulder, Michael A, Thomas R Loveland, David P Roy, Christopher J Crawford, Jeffrey G Masek, Curtis E Woodcock, Richard G Allen, et al. 2019. “Current Status of Landsat Program, Science, and Applications.” Remote Sensing of Environment 225: 127–47.\n\n\nWulder, Michael A, Jeffrey G Masek, Warren B Cohen, Thomas R Loveland, and Curtis E Woodcock. 2012. “Opening the Archive: How Free Data Has Enabled the Science and Monitoring Promise of Landsat.” Remote Sensing of Environment 122: 2–10.\n\n\nZhang, Xiaoyang, Mark A Friedl, Crystal B Schaaf, Alan H Strahler, John CF Hodges, Feng Gao, Bradley C Reed, and Alfredo Huete. 2003. “Monitoring Vegetation Phenology Using MODIS.” Remote Sensing of Environment 84 (3): 471–75.\n\n\nZhao, Qiang, Le Yu, Xuecao Li, Dailiang Peng, Yongguang Zhang, and Peng Gong. 2021. “Progress and Trends in the Application of Google Earth and Google Earth Engine.” Remote Sensing 13 (18): 3778.\n\n\nZhu, Zhe, Shixiong Wang, and Curtis E Woodcock. 2015. “Improvement and Expansion of the Fmask Algorithm: Cloud, Cloud Shadow, and Snow Detection for Landsats 4–7, 8, and Sentinel 2 Images.” Remote Sensing of Environment 159: 269–77.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#footnotes",
    "href": "chapters/image-data.html#footnotes",
    "title": "3  Satellite Imagery Data",
    "section": "",
    "text": "Sputnik 1: https://en.wikipedia.org/wiki/Sputnik_1 Should we use WikiPedia for references in the BoI?↩︎\nLandsat 1: https://en.wikipedia.org/wiki/Landsat_1↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  },
  {
    "objectID": "chapters/image-data.html#introduction",
    "href": "chapters/image-data.html#introduction",
    "title": "3  Satellite Imagery Data",
    "section": "",
    "text": "WarningReview comment\n\n\n\nSP: A simplified introduction :\n“Open a picture on your computer and zoom in until you cannot anymore. What you see are pixels—the building blocks of any digital image. Your picture captures visible light. Satellite data does the same thing, but for the entire world.Satellite imagery is”raster” data: a grid where each pixel holds a value representing a specific measurement. Satellites carry multiple sensors, each designed to capture different types of information—spectral (which wavelengths?), spatial (how detailed?), temporal (how often?), and radiometric (how precise?). Unlike aircraft surveys or ground-based field measurements, satellites provide consistent, large-scale coverage across regions and continents, enabling systematic monitoring over time.”",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Satellite Imagery Data</span>"
    ]
  }
]