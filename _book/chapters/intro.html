<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francisco Rowe">

<title>2&nbsp; Introduction: Why Imagery, Why Now? – Book of Imagery</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/image-data.html" rel="next">
<link href="../index.html" rel="prev">
<link href="../assets/Imago-logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-70a47bd5681a7291082a5b9f83d58762.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/intro.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction: Why Imagery, Why Now?</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Book of Imagery</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/Imago-SDRUK/boi" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preface</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction: Why Imagery, Why Now?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/image-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Satellite Imagery Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01_use-case-x.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Use Case 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/synthesis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Synthesis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/way-forward.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Way Forward</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro_promise" id="toc-sec-intro_promise" class="nav-link active" data-scroll-target="#sec-intro_promise"><span class="header-section-number">2.1</span> The promise of imagery for social science and policy</a></li>
  <li><a href="#sec-intro_unique" id="toc-sec-intro_unique" class="nav-link" data-scroll-target="#sec-intro_unique"><span class="header-section-number">2.2</span> What makes satellite imagery unique?</a>
  <ul class="collapse">
  <li><a href="#comprehensive-coverage" id="toc-comprehensive-coverage" class="nav-link" data-scroll-target="#comprehensive-coverage"><span class="header-section-number">2.2.1</span> Comprehensive coverage</a></li>
  <li><a href="#spatial-resolution" id="toc-spatial-resolution" class="nav-link" data-scroll-target="#spatial-resolution"><span class="header-section-number">2.2.2</span> Spatial resolution</a></li>
  <li><a href="#temporal-frequency-and-timeliness" id="toc-temporal-frequency-and-timeliness" class="nav-link" data-scroll-target="#temporal-frequency-and-timeliness"><span class="header-section-number">2.2.3</span> Temporal frequency and timeliness</a></li>
  <li><a href="#retrospective-power" id="toc-retrospective-power" class="nav-link" data-scroll-target="#retrospective-power"><span class="header-section-number">2.2.4</span> Retrospective power</a></li>
  <li><a href="#robustness-to-common-data-biases" id="toc-robustness-to-common-data-biases" class="nav-link" data-scroll-target="#robustness-to-common-data-biases"><span class="header-section-number">2.2.5</span> Robustness to common data biases</a></li>
  <li><a href="#multi-sensor-richness" id="toc-multi-sensor-richness" class="nav-link" data-scroll-target="#multi-sensor-richness"><span class="header-section-number">2.2.6</span> Multi-sensor richness</a></li>
  <li><a href="#a-unique-source-of-social-data" id="toc-a-unique-source-of-social-data" class="nav-link" data-scroll-target="#a-unique-source-of-social-data"><span class="header-section-number">2.2.7</span> A unique source of social data</a></li>
  </ul></li>
  <li><a href="#sec-intro_whynow" id="toc-sec-intro_whynow" class="nav-link" data-scroll-target="#sec-intro_whynow"><span class="header-section-number">2.3</span> Why now? The timely confluence of technological advances and shifting societal needs</a>
  <ul class="collapse">
  <li><a href="#proliferation-and-democratisation-of-satellites" id="toc-proliferation-and-democratisation-of-satellites" class="nav-link" data-scroll-target="#proliferation-and-democratisation-of-satellites"><span class="header-section-number">2.3.1</span> Proliferation and democratisation of satellites</a></li>
  <li><a href="#advances-in-resolution-and-sensor-capability" id="toc-advances-in-resolution-and-sensor-capability" class="nav-link" data-scroll-target="#advances-in-resolution-and-sensor-capability"><span class="header-section-number">2.3.2</span> Advances in resolution and sensor capability</a></li>
  <li><a href="#revolution-in-computation-and-artificial-intelligence" id="toc-revolution-in-computation-and-artificial-intelligence" class="nav-link" data-scroll-target="#revolution-in-computation-and-artificial-intelligence"><span class="header-section-number">2.3.3</span> Revolution in computation and artificial intelligence</a></li>
  <li><a href="#easier-access-and-integration-with-existing-data-ecosystems" id="toc-easier-access-and-integration-with-existing-data-ecosystems" class="nav-link" data-scroll-target="#easier-access-and-integration-with-existing-data-ecosystems"><span class="header-section-number">2.3.4</span> Easier access and integration with existing data ecosystems</a></li>
  <li><a href="#growing-societal-demand-for-timely-granular-evidence" id="toc-growing-societal-demand-for-timely-granular-evidence" class="nav-link" data-scroll-target="#growing-societal-demand-for-timely-granular-evidence"><span class="header-section-number">2.3.5</span> Growing societal demand for timely, granular evidence</a></li>
  <li><a href="#an-inflection-point-for-social-research-and-policy" id="toc-an-inflection-point-for-social-research-and-policy" class="nav-link" data-scroll-target="#an-inflection-point-for-social-research-and-policy"><span class="header-section-number">2.3.6</span> An inflection point for social research and policy</a></li>
  </ul></li>
  <li><a href="#sec-intro_case" id="toc-sec-intro_case" class="nav-link" data-scroll-target="#sec-intro_case"><span class="header-section-number">2.4</span> The case for social science and policy use</a>
  <ul class="collapse">
  <li><a href="#persistent-gaps-in-evidence" id="toc-persistent-gaps-in-evidence" class="nav-link" data-scroll-target="#persistent-gaps-in-evidence"><span class="header-section-number">2.4.1</span> Persistent gaps in evidence</a></li>
  <li><a href="#applications-across-domains" id="toc-applications-across-domains" class="nav-link" data-scroll-target="#applications-across-domains"><span class="header-section-number">2.4.2</span> Applications across domains</a></li>
  <li><a href="#complementarity-and-integration" id="toc-complementarity-and-integration" class="nav-link" data-scroll-target="#complementarity-and-integration"><span class="header-section-number">2.4.3</span> Complementarity and integration</a></li>
  <li><a href="#towards-useful-usable-and-used-imagery" id="toc-towards-useful-usable-and-used-imagery" class="nav-link" data-scroll-target="#towards-useful-usable-and-used-imagery"><span class="header-section-number">2.4.4</span> Towards <em>useful</em>, <em>usable</em> and <em>used</em> imagery</a></li>
  </ul></li>
  <li><a href="#sec-intro_barriers" id="toc-sec-intro_barriers" class="nav-link" data-scroll-target="#sec-intro_barriers"><span class="header-section-number">2.5</span> Barriers and challenges</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Imago-SDRUK/boi/edit/main/chapters/intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/Imago-SDRUK/boi/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction: Why Imagery, Why Now?</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Francisco Rowe </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="sec-intro_promise" class="level2 page-columns page-full" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-intro_promise"><span class="header-section-number">2.1</span> The promise of imagery for social science and policy</h2>

<!-- - Set the scene: social scientists and policymakers face urgent questions (inequalities, sustainability, wellbeing, climate adaptation) but lack timely and spatially rich data.\ -->
<!-- - Position satellite imagery as an underused yet transformative source. \ -->
<!-- - Brief anecdote/example (e.g., using night-time lights for economic growth, greenspace for health outcomes) to show relevance. \ -->
<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most references are entered manually, we need to add them properly through BibTeX before releasing the first version.</p>
</div>
</div></div><p>We are living in a fast changing society needing timely, spatially granular, and consistent information to adequately address complex social, economic, climatic, health and policy challenges. Challenges such as widening inequalities, uneven economic development, environmental vulnerability and persistent health disparities represent fundamental questions about places and how they change. Traditional sources, including censuses, household surveys and administrative registers remain indispensable. Yet, they are limited by cost, infrequency, selective coverage and latency in their collection and release. As a result, decision-makers and researchers often lack the evidence needed to monitor rapid change, anticipate emerging challenges, and evaluate the local effects of interventions.</p>
<p>Satellite imagery offers a powerful and underexploited data solution. For more than half a century, satellites have orbited the Earth, capturing a detailed record of its surface and atmosphere. Initially designed for environmental monitoring, these data now represent an unparalleled observational archive of human and natural systems. Imagery captures the physical fabric of places, density of buildings, presence of green and blue spaces, road networks and informal settlements. It does this consistently across the globe and can capture change at multiple scales from local neighbourhood areas to national borders or entire continents. Unlike most traditional forms of social data, which are geographically fragmented and slow to update, imagery is comprehensive, timely and replicable.</p>
<p>An increasing volume of research has already demonstrated the promise of satellite imagery. Night-time lights have been used as proxies for economic activity and inequality across the globe (Henderson, Storeygard, &amp; Weil, 2012) and sense changes in urban energy consumption (Rowe, Robinson &amp; Patias 2022). Multispectral imagery has enabled the mapping of urban deprivation (Arribas-Bel, Patino, &amp; Duque, 2017) and the monitoring of land use change in fast-growing regions (Brown et al., 2004). More recent advances in computer vision and machine learning further enhance our capacity to derive meaningful indicators from raw pixels, opening a new frontier for social research and policy. The challenge (and opportunity) lies in integrating these data into the mainstream to illuminate processes that have long remained in the shadows, to take satellites into the standard toolkit. Key to this challenge is making imagery more accessible and usable.</p>
</section>
<section id="sec-intro_unique" class="level2 page-columns page-full" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-intro_unique"><span class="header-section-number">2.2</span> What makes satellite imagery unique?</h2>
<!-- - Comprehensiveness: global coverage, consistent revisits.\ -->
<!-- - Spatial detail: from 30m to sub-metre, enabling local and neighbourhood-level insights. \ -->
<!-- - Timeliness: daily to weekly revisits, enabling nowcasting. \ -->
<!-- - Retrospective power: archives spanning decades (e.g., Landsat since 1970s). \ -->
<!-- - Bias-resilience: unlike surveys/app data, less affected by self-selection. \ -->
<!-- - Multi-sensor richness: optical, SAR, LiDAR, thermal, hyperspectral. \ -->

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>DAB: Consider if in sections 2.2 and 2.3, the text would flow better <em>without</em> sub-headings (e.g., 2.2.X). They all contain a single paragraph and perhaps the narrative would come together a bit better without the subheadings (the thematic nature of each paragraph is clear and super good I think, maybe it doesn’t need a subheading).</p>
</div>
</div><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>SP: I agree with DAB about having no sub heads. However, if subheads are required/felt necessary, they can be more `thematised’. So we can club comprehensive coverage + multi sensor coverage+ spatial resolution, temporal frequency + timeliness + retrospective power, and then conclude with the robustness. The story then reads like - satellite data has comprehensive coverage over space and time, and it can do better than surveys in some cases. Therefore, it is robust. That might improve the flow of this section.</p>
</div>
</div></div>
<p>Satellite imagery is unlike most other forms of data used in the social sciences. The uniqueness of satellite imagery comes in the way multiple distinctive attributes compound to provide an observational resource that is comprehensive, consistent, granular and increasingly accessible. These qualities allow imagery to transcend the limitations of conventional social data sources and open new opportunities for analysis and policymaking.</p>
<section id="comprehensive-coverage" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="comprehensive-coverage"><span class="header-section-number">2.2.1</span> Comprehensive coverage</h3>
<p>Satellites view the entire Earth, offering data that extend across countries, regions and communities. This comprehensiveness can complement traditional data streams, like surveys, which are often limited by sample size, response bias or geographic reach. They can also enhance administrative registers in territories where governments maintain robust data infrastructures. Satellite imagery generates systematic records of all visible surfaces within its sensor range, covering remote rural areas, informal settlements and conflict-affected regions where social data are especially scarce (Kugler et al., 2019).</p>
</section>
<section id="spatial-resolution" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="spatial-resolution"><span class="header-section-number">2.2.2</span> Spatial resolution</h3>
<p>Modern satellite platforms capture imagery at a range of spatial resolutions from kilometres to less than one metre per pixel. Coarser imagery provides consistent monitoring of land cover and climate-related variables at regional and national scales. Very high-resolution imagery can reveal building footprints, street patterns and even the configuration of green spaces at the neighbourhood level. This multi-scale capacity makes imagery a flexible resource: it can illuminate both macro-level transformations such as urban sprawl (Brown et al., 2004) and micro-scale differences in the built environment associated with health or wellbeing (Metzler et al., 2023).</p>
</section>
<section id="temporal-frequency-and-timeliness" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="temporal-frequency-and-timeliness"><span class="header-section-number">2.2.3</span> Temporal frequency and timeliness</h3>
<p>Satellite missions provide regular and predictable revisits ranging from daily (e.g.&nbsp;PlanetScope) to a few days or weeks (e.g.&nbsp;Sentinel-2 and Landsat). This cadence allows researchers and policymakers to generate consistent time series and monitor rapid changes in near real-time. For example, vegetation indices derived from multispectral imagery can track seasonal dynamics in urban greenness, while radar imagery can detect flood extents immediately after a storm. Such timeliness is difficult to achieve with traditional data sources, which are often updated only every few years. There is often a trade-off in satellite data between resolution and frequency, but technological advances such as nanosat constellations<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> are constantly pushing outwards the frontier at which this trade-off takes place.</p>
</section>
<section id="retrospective-power" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="retrospective-power"><span class="header-section-number">2.2.4</span> Retrospective power</h3>
<p>Satellite programmes, such as Landsat, have been operating since the 1970s, creating an unparalleled archive of the Earth’s surface. These historical datasets allow researchers to reconstruct long-term patterns of land cover, urbanisation and environmental change, offering insights into trajectories that no survey or census could capture. The ability to ``look back in time’’ makes imagery especially valuable for understanding the cumulative effects of policies, economic shifts and climate change across decades (National Research Council, 1998). It also allows to fill the gaps that the lack of temporal consistency of some traditional social datasets introduce.</p>
</section>
<section id="robustness-to-common-data-biases" class="level3" data-number="2.2.5">
<h3 data-number="2.2.5" class="anchored" data-anchor-id="robustness-to-common-data-biases"><span class="header-section-number">2.2.5</span> Robustness to common data biases</h3>
<p>Unlike survey data, which rely on voluntary participation and may exclude hard-to-reach groups, satellite imagery does not require human consent or response to be generated. This makes it relatively immune to self-selection bias and more representative across space. While imagery has its own challenges (e.g.&nbsp;cloud cover and sensor noise), its systematic and global character ensures a level of consistency that complements traditional data sources (De Sherbinin et al., 2002).</p>
</section>
<section id="multi-sensor-richness" class="level3" data-number="2.2.6">
<h3 data-number="2.2.6" class="anchored" data-anchor-id="multi-sensor-richness"><span class="header-section-number">2.2.6</span> Multi-sensor richness</h3>
<p>Imagery is not limited to visible light. Satellites measure across the electromagnetic spectrum, producing data on heat, vegetation health, surface water and air pollutants. Synthetic Aperture Radar (SAR) captures structural features through cloud and darkness; and hyperspectral sensors enable fine-grained detection of material properties. This diversity of sensors allows for the derivation of novel indicators, for example, from rooftop solar potential to urban heat island intensity that can directly inform pressing policy agendas in sustainability, prosperity and wellbeing (Deilami and Kamruzzaman, 2017).</p>
</section>
<section id="a-unique-source-of-social-data" class="level3 page-columns page-full" data-number="2.2.7">
<h3 data-number="2.2.7" class="anchored" data-anchor-id="a-unique-source-of-social-data"><span class="header-section-number">2.2.7</span> A unique source of social data</h3>

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>DAB: This is section is very good. I wonder if we should consider an additional feature to the boxes (like the one below) that highlights quotes from the text that we’d like the reader to be “imprinted on”.</p>
</div>
</div></div><p>Together, the above identified attributes position satellite imagery as a uniquely powerful form of smart data. Its comprehensiveness, resolution, timeliness, retrospective depth and sensor diversity create a multidimensional evidence base that is unmatched by conventional sources. What makes imagery transformative is not just its technical sophistication, but its capacity to bridge long-standing evidence gaps in the social sciences and policymaking, providing the foundations for more informed and timely decisions.</p>

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-tip callout-titled" title="Box 1.1: Mapping Urban Greenspace Inequalities">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Box 1.1: Mapping Urban Greenspace Inequalities
</div>
</div>
<div class="callout-body-container callout-body">
<p>Urban greenspace is increasingly recognised as a determinant of health and wellbeing. Yet official statistics on its distribution are often fragmented, inconsistent or outdated. Satellite imagery provides a systematic alternative. Using freely available Sentinel-2 multispectral data, researchers can derive the Normalised Difference Vegetation Index (NDVI) to estimate vegetation cover at fine spatial scales. <mark>DAB: Update here when GreenSpace data product is available to link here</mark></p>
<p>By linking these imagery-derived measures to administrative health records, studies in the UK and elsewhere have shown systematic disparities in access to urban greenery, with deprived communities often having less exposure (Rugel et al., 2019; <strong>[REF]</strong>). For policymakers, this information is critical: it identifies <code>green deserts</code> within cities, supports the design of equitable planning policies and provides indicators to monitor the effectiveness of urban greening initiatives.</p>
<p>The key advantage is comprehensiveness and comparability. Unlike local audits or surveys, satellite imagery captures greenspace consistently across entire cities and regions, enabling cross-neighbourhood benchmarking and long-term monitoring. This makes it a unique input into strategies for healthy and sustainable urban development.</p>
</div>
</div></div></section>
</section>
<section id="sec-intro_whynow" class="level2 page-columns page-full" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-intro_whynow"><span class="header-section-number">2.3</span> Why now? The timely confluence of technological advances and shifting societal needs</h2>
<!-- - Proliferation of satellites: growth in number, lower launch costs. \ -->
<!-- - Improved resolution & new sensors: finer spatial, temporal, and spectral resolution. \ -->
<!-- - Computational revolutions: AI/ML, cloud computing, open data platforms. \ -->
<!-- - Accessibility: open missions (Sentinel, Landsat), user-friendly APIs. \ -->
<!-- - Integration readiness: linkages with surveys, administrative data, mobile phone data. \ -->
<!-- - Key message: Imagery is moving from niche to mainstream, with lowered barriers to entry. \ -->
<p>For decades, the potential of satellite imagery to transform the social sciences and inform public policy has been recognised (Rindfuss &amp; Stern, 1998; National Research Council, 1998). Yet until recently, this potential remained largely aspirational. The barriers were formidable: imagery was expensive, technically complex and difficult to process at scale; expertise was confined to environmental sciences and engineering, and the social science community lacked both the tools and the training to make effective use of complex and unstructured imagery data; in addition, the state-of-the-art technology did not allow the detail required to identify features and processes of interest in social contexts. Recently, key developments have transformed the landscape. We are witnessing a convergence of technological, institutional and societal changes that, together, create the right conditions for mainstreaming imagery in social research and policy.</p>

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-tip callout-titled" title="Box 1.2: From Pixels to Policy: Monitoring Rooftop Solar for Net Zero">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Box 1.2: From Pixels to Policy: Monitoring Rooftop Solar for Net Zero
</div>
</div>
<div class="callout-body-container callout-body">
<p><mark>DAB: I’d only use this example if/when we know with certainty we’ll be getting into this space with a data product. Until then, I’d use a different example.</mark></p>
<p>A example that illustrates why satellite imagery is at an inflection point for social science and policy. Achieving net zero requires detailed knowledge of how households and businesses are adopting renewable technologies, yet official statistics on rooftop solar installation are often incomplete, delayed, or inconsistently reported across regions.</p>
<p>Recent advances in computer vision and high-resolution imagery now allow automated detection of solar panels from space. Convolutional neural networks can be trained to recognise the distinctive spectral and geometric patterns of panels, producing accurate counts at building level and aggregating them to neighbourhoods or local authorities (e.g.&nbsp;Malof et al., 2016; Yu et al., 2018). When combined with socio-economic and housing data, these imagery-derived indicators help identify where adoption is lagging, highlight inequalities in access to green technology and guide targeted policy incentives.</p>
<p>Crucially, these analyses can be updated regularly, tracking quarterly or even monthly uptake, and providing policymakers with near real-time evidence that would be prohibitively costly through surveys or administrative reporting alone. This example demonstrates how the convergence of new sensors, machine learning and demand for localised evidence makes imagery not just a complementary resource but a core component of the evidence infrastructure for sustainability and wellbeing.</p>
</div>
</div></div><section id="proliferation-and-democratisation-of-satellites" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="proliferation-and-democratisation-of-satellites"><span class="header-section-number">2.3.1</span> Proliferation and democratisation of satellites</h3>
<p>The number of satellites orbiting the Earth has grown exponentially. After decades of roughly 150 satellite launches per year (1957–2012), annual launches surged to about 600 in 2019, 1,200 in 2020, and 2,470 in 2022 <span class="citation" data-cites="UNOOSA2023">(<a href="references.html#ref-UNOOSA2023" role="doc-biblioref">United Nations Office for Outer Space Affairs (UNOOSA) 2023</a>)</span>. Public programmes such as the European Space Agency’s Sentinel missions and NASA’s Landsat archive provide high-quality data freely and openly, while private constellations like Planet or Maxar deliver near-daily high-resolution imagery. Launch costs have plummeted, fuelled by commercial providers and advances in satellite miniaturisation <span class="citation" data-cites="sweeting2018modern">(<a href="references.html#ref-sweeting2018modern" role="doc-biblioref">Sweeting 2018</a>)</span>. The result is not only more satellites but more diverse sensors—optical, radar, hyperspectral and thermal offering unparalleled coverage of the Earth’s surface. What was once the preserve of specialised agencies is now accessible to researchers, policymakers and even the general public.</p>
</section>
<section id="advances-in-resolution-and-sensor-capability" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="advances-in-resolution-and-sensor-capability"><span class="header-section-number">2.3.2</span> Advances in resolution and sensor capability</h3>
<p>Alongside this expansion of satellite availability has come a dramatic improvement in the quality of imagery. Spatial resolution has increased from kilometres to sub-metre detail; temporal resolution has improved to daily or even multiple daily revisits; and spectral resolution has grown into hyper-spectral imagery that enables the measurement of heat, vegetation stress, air pollutants and urban morphology. These advances expand the analytical frontier: for example, <mark>DAB: we already have this example a couple of times above, consider including another one</mark> <mark>SP: I changed it</mark> tracking micro-greenspaces <span class="citation" data-cites="ramdani2024very">(<a href="references.html#ref-ramdani2024very" role="doc-biblioref">Ramdani 2024</a>)</span>, or monitoring the impacts of heatwaves on vulnerable populations <strong>[REF]</strong>, or estimating contamination in agricultural soils <span class="citation" data-cites="yao2024estimating">(<a href="references.html#ref-yao2024estimating" role="doc-biblioref">Yao et al. 2024</a>)</span>. Such detail is key for understanding the intersection of environmental exposures, health and social inequality at scales that matter for policy.</p>
</section>
<section id="revolution-in-computation-and-artificial-intelligence" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="revolution-in-computation-and-artificial-intelligence"><span class="header-section-number">2.3.3</span> Revolution in computation and artificial intelligence</h3>
<p>Raw pixels alone are not enough. The primary value of imagery relates to the transformation of raw pixels into meaningful indicators. This is what <em>Imago</em> terms the “pixel-to-metric” challenge. Until recently, this process was limited by computational bottlenecks. Advances in machine learning and computer vision, combined with the rise of cloud computing and high-performance infrastructures, have fundamentally altered this landscape. Modern neural networks can extract building footprints, classify land cover or estimate deprivation with remarkable accuracy <span class="citation" data-cites="arribasbel2017remote">(<a href="references.html#ref-arribasbel2017remote" role="doc-biblioref">Arribas-Bel 2017</a>)</span>. Cloud platforms such as Google Earth Engine make it possible to analyse terabytes of imagery without local supercomputers. And the open source revolution that has powered many of these advances has democratised access to knowledge that used to required extremely advanced domain training. These factors have all contributed to lowering the barrier to entry for social researchers and policymakers.</p>
</section>
<section id="easier-access-and-integration-with-existing-data-ecosystems" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="easier-access-and-integration-with-existing-data-ecosystems"><span class="header-section-number">2.3.4</span> Easier access and integration with existing data ecosystems</h3>
<p>Equally transformative are the changes in data access. Imagery has also benefitted from the rise of data science over the last two decades, and is increasingly delivered through portals, APIs and interoperable formats (Jacobsen et al., 2020). This accessibility means that imagery can be linked to household surveys, administrative records or longitudinal cohort studies, allowing researchers to integrate contextual measures of environment, housing, or infrastructure into existing datasets. Such integration bridges the long-standing gap between social data on individuals and contextual data on places, creating powerful opportunities for spatially-explicit analysis and evidence-based policymaking. Yet, while an increasing number of satellite datasets are more accessible, their sheer volume and complex, unstructured nature remain a major challenge for most social scientists and policy makers to use and analyse imagery. This is a key barrier that <em>Imago</em> will tackle.</p>
</section>
<section id="growing-societal-demand-for-timely-granular-evidence" class="level3" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="growing-societal-demand-for-timely-granular-evidence"><span class="header-section-number">2.3.5</span> Growing societal demand for timely, granular evidence</h3>
<p>Technological advances alone would not be relevant if demand was absent. The societal context has shifted dramatically. Some of the most pressing challenges, including the climate emergency, health inequalities, housing crises and uneven regional development, all require data that are timely, spatially detailed and robust. Policymakers seek indicators that can capture the dynamics of local communities, monitor change in near real time and evaluate the impacts of interventions. Imagery is uniquely placed to meet this demand, offering consistent coverage at scales from a national to neighbourhood scale. In this sense, the <em>supply</em> of new imagery technologies is met with an urgent <em>demand</em> for better evidence in sustainability, prosperity and wellbeing.</p>
</section>
<section id="an-inflection-point-for-social-research-and-policy" class="level3" data-number="2.3.6">
<h3 data-number="2.3.6" class="anchored" data-anchor-id="an-inflection-point-for-social-research-and-policy"><span class="header-section-number">2.3.6</span> An inflection point for social research and policy</h3>
<p>Taken together, these changes may mark an inflection point. The barriers that historically confined imagery to niche environmental applications are being lowered. The convergence of cheaper and plentiful satellites, improved sensors, powerful computational methods, more accessible platforms, and pressing policy needs creates a window of opportunity. For the first time, imagery can become a mainstream data source for social research and policymaking. The challenge in front of us is to ensure the opportunity is seized: to build the infrastructure, capacity, and community that can make imagery usable, useful, and used across disciplines.</p>
</section>
</section>
<section id="sec-intro_case" class="level2 page-columns page-full" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-intro_case"><span class="header-section-number">2.4</span> The case for social science and policy use</h2>
<!-- - Persistent data gaps: inequalities, wellbeing, prosperity, urban development.\ -->
<!-- - Policy needs: localised, timely, reliable evidence.\ -->
<!-- - Existing uptake: economics (Henderson et al., 2012), demography (Weeks et al., 2000), health-environment (greenspace studies).\ -->
<!-- - Limitations of conventional data: surveys (expensive, slow), administrative data (uneven coverage, privacy concerns), app data (bias). \ -->
<!-- - How imagery complements existing sources: linking to survey microdata, augmenting spatial models, providing contextual measures. \ -->
<!-- - Highlight IMAGO’s mission: to make imagery usable, useful, and used for these communities. \ -->

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-tip callout-titled" title="Box 1.3: Detecting Informal Settlements and Housing Inequality for Inclusive Policy">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Box 1.3: Detecting Informal Settlements and Housing Inequality for Inclusive Policy
</div>
</div>
<div class="callout-body-container callout-body">
<p>Currently, informal settlements house over a billion people globally, with this number expected to increase substantially over the next 30 years (United Nations, 2023). Yet, they are often absent from official statistics and maps. This invisibility perpetuates exclusion, making it difficult for governments and international organisations to target investments in housing, sanitation, and health.</p>
<p>Satellite imagery offers a way forward. High-resolution optical data, combined with machine learning classifiers, can detect the dense, irregular patterns characteristic of informal housing. Studies in sub-Saharan Africa and South Asia have demonstrated that imagery-based maps of settlement extent align closely with ground surveys, but can be produced faster, at lower cost, and with full coverage (Kuffer et al., 2016; Mahabir et al., 2018).</p>
<p>For policymakers, this capacity is transformative. Imagery can reveal previously unmapped communities, track their expansion over time, and help allocate resources more equitably. By integrating imagery with household surveys or administrative records, it becomes possible to link population characteristics with environmental exposures, providing a fuller picture of vulnerability and need.</p>
<p>Importantly, this is also relevant in advanced economies such as the UK, where fine-grained spatial data can identify pockets of deprivation, housing precarity, or poor living conditions. Deriving granular insights from satellite data can enhance local authorities’ ability to design targeted, place-based interventions, aligning with the UK’s broader Levelling Up agenda.</p>
<p>This example illustrates the central case for imagery in social science and policy. It addresses critical data gaps in contexts where conventional sources are absent, unreliable or prohibitively expensive, enabling more inclusive and responsive decision-making.</p>
</div>
</div></div><p>Every second of human existence is now recorded from space. The challenge is no longer availability — it’s use. Despite a world of data being generated, a persistent gap remains between what satellites capture and what reaches policy makers’ hands. Pioneers have already shown how imagery can move the needle. Yet broader impact requires removing the frictions that keep this data out of reach. Imago bridges this gap.</p>
<section id="persistent-gaps-in-evidence" class="level3 page-columns page-full" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="persistent-gaps-in-evidence"><span class="header-section-number">2.4.1</span> Persistent gaps in evidence</h3>

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>SP: I feel this sub section is too far down, it should be up in the beginning. It is the gap we are bridging, and therefore the raison d’etre for the BoI. If we justify it in the penultimate subsection, it feels too late to talk about it. My vote would be to put it in the intro to 2.2.</p>
</div>
</div></div><p>Across social research and policy, an enduring challenge is the lack of timely, reliable and spatially detailed data. Inequalities in health, prosperity and wellbeing often manifest at local scales: between neighbourhoods, across urban–rural divides or within regions. Yet, the data streams traditionally used to study these questions rarely provide the necessary resolution or frequency. Censuses are comprehensive but infrequent. Household surveys are costly and often geographically limited. Administrative data can be inconsistent or inaccessible due to privacy and governance restrictions. These gaps are especially acute in areas where policy demand is greatest: monitoring the uneven impacts of climate hazards, evaluating local housing markets, or designing interventions to address health disparities.</p>
<p>Satellite imagery directly addresses these shortcomings. Its global, repeated coverage provides a spatial and temporal granularity rarely achievable with traditional data, offering opportunities to fill evidence gaps that constrain research and policymaking. Just as importantly, this value is entirely additive rather than substitutive: satellite data complement traditional social data, help <em>stretch</em> their value, and provide a multiplier effect that increases the value proposition of traditional data.</p>
</section>
<section id="applications-across-domains" class="level3 page-columns page-full" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="applications-across-domains"><span class="header-section-number">2.4.2</span> Applications across domains</h3>

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>DAB: This section feel a bit unfinished. Perhaps it needs a better intro to show it is a list of areas where satellites have already moved the needle.</p>
</div>
</div></div><p>The potential of imagery has been demonstrated through a growing body of research showcasing its promise across multiple relevant domains, for example:</p>
<p><em>Economic development and inequality</em>: Night-time light intensity has been used as a proxy for local economic activity, enabling estimates of growth in regions lacking reliable national accounts (Henderson et al., 2012). Studies combine multispectral imagery with machine learning to predict poverty at high spatial resolution (e.g.&nbsp;Jean et al., 2016), supporting targeted development interventions.</p>
<p><em>Urbanisation and housing</em>: Imagery provides indicators of urban expansion, building density, and settlement form. These measures are critical for understanding sprawl, housing affordability, and infrastructure provision (Brown et al., 2004). They also allow policymakers to track progress towards sustainable urban development goals.</p>
<p><em>Environment and health</em>: Imagery-derived measures of greenness, heat and pollution exposure can be derived and linked to individual and population health outcomes. These insights reveal systematic inequalities in environmental quality, with direct implications for urban planning and public health policy <span class="citation" data-cites="Venter2023">(<a href="references.html#ref-Venter2023" role="doc-biblioref">Venter et al. 2023</a>)</span>.</p>
<p><em>Disaster response and climate adaptation</em>: Rapid imagery analysis following floods, fires, or earthquakes enables near-real-time damage assessment. Such evidence supports humanitarian response and informs longer-term resilience planning <span class="citation" data-cites="Shafapourtehrany2023">(<a href="references.html#ref-Shafapourtehrany2023" role="doc-biblioref">Shafapourtehrany et al. 2023</a>)</span>.</p>
</section>
<section id="complementarity-and-integration" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="complementarity-and-integration"><span class="header-section-number">2.4.3</span> Complementarity and integration</h3>
<p>The greatest potential of imagery lies in data integration with other data sources. Imagery-derived indicators can be linked with household or cohort surveys to provide rich contextual measures of local environment, infrastructure and housing conditions. For example, linking greenspace indices to health records can illuminate associations between neighbourhood environments and mental wellbeing. Similarly, combining imagery-based poverty maps with demographic data can support more equitable allocation of resources.</p>
<p>This integrative capacity allows imagery to act as a bridge between individual-level data and the broader characteristics of places, enabling multilevel analyses that capture the interaction between people and their environments. It also aligns with the growing demand in policymaking for place-based evidence that reflects the lived experience of communities rather than national averages <span class="citation" data-cites="OECD2025">(<a href="references.html#ref-OECD2025" role="doc-biblioref">OECD 2025</a>)</span>.</p>
</section>
<section id="towards-useful-usable-and-used-imagery" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="towards-useful-usable-and-used-imagery"><span class="header-section-number">2.4.4</span> Towards <em>useful</em>, <em>usable</em> and <em>used</em> imagery</h3>
<p>The case for social research and policy use can be summarised as a matter of timing and translation. The technological advances described in <a href="#sec-intro_whynow" class="quarto-xref"><span>Section 2.3</span></a> imply that, for the first time, imagery is poised to become a routine part of the evidence base. But realising this potential requires making imagery usable, useful, and used:</p>
<ul>
<li><p>Useful, by co-producing data products with stakeholders to ensure relevance to research and policy questions.</p></li>
<li><p>Usable, by lowering technical barriers through open platforms, user-friendly interfaces, and interoperable data formats.</p></li>
<li><p>Used, by embedding imagery into established data ecosystems, training communities of practice, and demonstrating impact through visible policy applications.</p></li>
</ul>
<p>By addressing these three pillars, imagery can evolve from a promising niche resource to a cornerstone of evidence-based social science and policymaking. The case is not only academic, it is practical and aligned with the growing demand for timely, localised and equitable data infrastructures.</p>
</section>
</section>
<section id="sec-intro_barriers" class="level2 page-columns page-full" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="sec-intro_barriers"><span class="header-section-number">2.5</span> Barriers and challenges</h2>

<div class="no-row-height column-margin column-container"><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>DAB: add additional pass</p>
</div>
</div><div class="callout callout-style-default callout-warning callout-titled" title="Review comment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Review comment
</div>
</div>
<div class="callout-body-container callout-body">
<p>SP: Made edits for flow and readability, please check.</p>
</div>
</div></div>
<p>Despite its promise, the widespread adoption of imagery in social science and policy remains constrained. There are broadly three classes of frictions - in processing, in understanding, and finally, in use.</p>
<p>Processing satellite data is <em>technically complex</em>, imagery is large in volume, stored in arcane formats, and requires technical expertise as well as specialist computing infrastructure to use. Extracting metrics from pixels involves terabytes of data and advanced processing pipelines.</p>
<p>There is a <em>translation gap</em>, in as much as a pixel is meaningless to a policy maker. The practitioners in need of this data do not work with raw imagery, but with interpretable measures (e.g.&nbsp;building density, greenspace exposure). The process of making raw imagery useful is often as demanding as processing it. Moreover, training in imagery analysis is largely absent from social science curricula, leaving potential users without the skills or resources to engage with these data.</p>
<p>Finally, using high resolution imagery requires careful consideration. The <em>ethical and governance</em> concers associated with these exercises are not trivial. Very high-resolution imagery raises privacy issues, particularly when combined with other sensitive data sources. Appropriate protocol for data access, analysis and output release are needed.</p>
<p>Despite decades of availability, these barriers have prevented imagery from entering the mainstream of social science and policy. Addressing these constraints requires sustained investment in infrastructure, capacity building and ethical governance. Imago has been designed to tackle these challenges.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-arribasbel2017remote" class="csl-entry" role="listitem">
Arribas-Bel, Jorge E. AND Duque, Daniel AND Patino. 2017. <span>“Remote Sensing-Based Measurement of Living Environment Deprivation: Improving Classical Approaches with Machine Learning.”</span> <em>PLOS ONE</em> 12 (5): 1–25. <a href="https://doi.org/10.1371/journal.pone.0176684">https://doi.org/10.1371/journal.pone.0176684</a>.
</div>
<div id="ref-OECD2025" class="csl-entry" role="listitem">
OECD. 2025. <em>Place-Based Policies for the Future</em>. OECD Regional Development Studies. Paris: OECD Publishing. <a href="https://doi.org/10.1787/e5ff6716-en">https://doi.org/10.1787/e5ff6716-en</a>.
</div>
<div id="ref-ramdani2024very" class="csl-entry" role="listitem">
Ramdani, Fatwa. 2024. <span>“A Very High-Resolution Urban Green Space from the Fusion of Microsatellite, SAR, and MSI Images.”</span> <em>Remote Sensing</em> 16 (8): 1366.
</div>
<div id="ref-Shafapourtehrany2023" class="csl-entry" role="listitem">
Shafapourtehrany, M., M. Batur, F. Shabani, B. Pradhan, B. Kalantar, and H. Özener. 2023. <span>“A Comprehensive Review of Geospatial Technology Applications in Earthquake Preparedness, Emergency Management, and Damage Assessment.”</span> <em>Remote Sensing</em> 15 (7): 1939. <a href="https://doi.org/10.3390/rs15071939">https://doi.org/10.3390/rs15071939</a>.
</div>
<div id="ref-sweeting2018modern" class="csl-entry" role="listitem">
Sweeting, Martin N. 2018. <span>“Modern Small Satellites-Changing the Economics of Space.”</span> <em>Proceedings of the IEEE</em> 106 (3): 343–61.
</div>
<div id="ref-UNOOSA2023" class="csl-entry" role="listitem">
United Nations Office for Outer Space Affairs (UNOOSA). 2023. <span>“Our Common Agenda Policy Brief 7: For All Humanity – the Future of Outer Space Governance.”</span> <a href="https://www.unoosa.org/res/oosadoc/data/documents/2023/a77/a77crp_1add_6_0_html/our-common-agenda-policy-brief-outer-space-en.pdf" class="uri">https://www.unoosa.org/res/oosadoc/data/documents/2023/a77/a77crp_1add_6_0_html/our-common-agenda-policy-brief-outer-space-en.pdf</a>.
</div>
<div id="ref-Venter2023" class="csl-entry" role="listitem">
Venter, Z. S., H. Figari, O. Krange, and V. Gundersen. 2023. <span>“Environmental Justice in a Very Green City: Spatial Inequality in Exposure to Urban Nature, Air Pollution and Heat in Oslo, Norway.”</span> <em>Science of The Total Environment</em> 858: 160193. <a href="https://doi.org/10.1016/j.scitotenv.2022.160193">https://doi.org/10.1016/j.scitotenv.2022.160193</a>.
</div>
<div id="ref-yao2024estimating" class="csl-entry" role="listitem">
Yao, Liwei, Mingjie Xu, Yihui Liu, Ruiqing Niu, Xueling Wu, and Yingxu Song. 2024. <span>“Estimating of Heavy Metal Concentration in Agricultural Soils from Hyperspectral Satellite Sensor Imagery: Considering the Sources and Migration Pathways of Pollutants.”</span> <em>Ecological Indicators</em> 158: 111416.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Fleets of shoe-box sized satellites that can obtain ever higher resolution at very high frequencies.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../index.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preface</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/image-data.html" class="pagination-link" aria-label="Satellite Imagery Data">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Satellite Imagery Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Imago | UKRI Imagery Data Service</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Imago-SDRUK/boi/edit/main/chapters/intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/Imago-SDRUK/boi/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>